# -*- coding: utf-8 -*-
import logging
import re
from django.core.management.base import BaseCommand
from django.db import transaction, models
from django.db.models import Count, OuterRef, Subquery
from django.db.models.functions import Coalesce
from django.utils import timezone 

# Èñ¢ÈÄ£„É¢„Éá„É´
from api.models import (
    RawApiData, AdultProduct, Genre, Actress, 
    Director, Maker, Label, Series
)

# „É¶„Éº„ÉÜ„Ç£„É™„ÉÜ„Ç£
from api.utils.adult.fanza_normalizer import normalize_fanza_data 
from api.utils.adult.entity_manager import get_or_create_entity 

logger = logging.getLogger('normalize_adult')

ENTITY_MODELS = [Maker, Label, Director, Series, Genre, Actress]
ENTITY_RELATION_KEYS = {
    Maker: 'maker', 
    Label: 'label', 
    Director: 'director', 
    Series: 'series',
    Genre: 'genres', 
    Actress: 'actresses'
}

class Command(BaseCommand):
    help = 'RawApiData„ÇíAdultProduct„Å∏Ê≠£Ë¶èÂåñ„Åó„ÄÅ„Éê„ÉÉ„ÉÅÂÜÖÈáçË§á„ÇíÊéíÈô§„Åó„Å¶UPSERT„Åó„Åæ„Åô„ÄÇ'

    def add_arguments(self, parser):
        parser.add_argument('--limit', type=int, help='Âá¶ÁêÜ‰ª∂Êï∞Âà∂Èôê')
        parser.add_argument('--source', type=str, default=None, help='FANZA or DMM')
        parser.add_argument('--re-run', action='store_true', help='migrated=True„ÅÆ„Éá„Éº„Çø„ÇÇÂÜçÂá¶ÁêÜ„Åô„Çã')

    def _optimize_url(self, url):
        """DMM/FANZA„ÅÆURL„ÇíÊúÄÈ´òÁîªË≥™„Å∏ÁΩÆÊèõ"""
        if not url:
            return ""
        if url.startswith('//'):
            url = 'https:' + url
            
        if 'pics.dmm.com' in url or 'pics.dmm.co.jp' in url:
            url = re.sub(r'p[s|t]\.jpg', 'pl.jpg', url, flags=re.IGNORECASE)
            url = re.sub(r'_[ms]\.jpg', '_l.jpg', url, flags=re.IGNORECASE)
        return url

    def handle(self, *args, **options):
        sources = [options['source'].upper()] if options['source'] else ['FANZA', 'DMM']
        re_run = options.get('re_run', False)
        
        for source in sources:
            self.stdout.write(self.style.NOTICE(f'\n--- {source} Ê≠£Ë¶èÂåñ„ÉªÈ´òÁîªË≥™Âåñ„Éï„Çß„Éº„Ç∫ÈñãÂßã ---'))
            
            filters = {'api_source': source}
            if not re_run:
                filters['migrated'] = False
                
            raw_qs = RawApiData.objects.filter(**filters).order_by('id')
            if options['limit']:
                raw_qs = raw_qs[:options['limit']]

            total = raw_qs.count()
            if total == 0:
                self.stdout.write(self.style.WARNING(f"{source} „ÅÆÂá¶ÁêÜÂØæË±°„Éá„Éº„Çø„ÅØ„ÅÇ„Çä„Åæ„Åõ„Çì„ÄÇ"))
                continue

            batch_size = 500
            # üöÄ ‰øÆÊ≠£: „É™„Çπ„Éà„Åß„ÅØ„Å™„ÅèËæûÊõ∏„Çí‰Ωø„ÅÑ„ÄÅproduct_id_unique„Çí„Ç≠„Éº„Å´„Åó„Å¶ÈáçË§á„Çí‰∏äÊõ∏„ÅçÊéíÈô§„Åô„Çã
            batch_dict = {} 
            batch_relations = {}
            processed_raw_ids = []

            for raw_instance in raw_qs:
                try:
                    p_list, r_list = normalize_fanza_data(raw_instance)
                    if not p_list:
                        raw_instance.migrated = True
                        raw_instance.save(update_fields=['migrated'])
                        continue

                    p_data = p_list[0]
                    r_data = r_list[0]
                    unique_id = p_data['product_id_unique']

                    # üöÄ ÁîªÂÉèURL„É™„Çπ„Éà„ÅÆÈ´òÁîªË≥™Âåñ
                    if 'image_url_list' in p_data:
                        optimized_urls = [self._optimize_url(u) for u in p_data['image_url_list']]
                        p_data['image_url_list'] = list(dict.fromkeys(filter(None, optimized_urls)))

                    # üé• ÂãïÁîª„Éá„Éº„Çø„ÅÆ„Éó„É¨„Éì„É•„ÉºÁîªÂÉè„ÇÇÈ´òÁîªË≥™Âåñ
                    if isinstance(p_data.get('sample_movie_url'), dict):
                        preview = p_data['sample_movie_url'].get('preview_image')
                        if preview:
                            p_data['sample_movie_url']['preview_image'] = self._optimize_url(preview)

                    p_data['api_source'] = source
                    p_data['updated_at'] = timezone.now()

                    # üöÄ ÈáçË§áÊéíÈô§: „Åô„Åß„Å´Âêå„ÅòID„Åå„ÅÇ„Çå„Å∞‰∏äÊõ∏„Åç„Åï„Çå„ÄÅSQL„Ç®„É©„Éº„ÇíÈò≤„Åê
                    batch_dict[unique_id] = p_data
                    batch_relations[unique_id] = r_data
                    processed_raw_ids.append(raw_instance.id)

                    if len(batch_dict) >= batch_size:
                        self._process_batch(list(batch_dict.values()), batch_relations, processed_raw_ids, source)
                        batch_dict, batch_relations, processed_raw_ids = {}, {}, []

                except Exception as e:
                    self.stdout.write(self.style.ERROR(f"Raw ID {raw_instance.id} Âá¶ÁêÜ„Ç®„É©„Éº: {e}"))

            if batch_dict:
                self._process_batch(list(batch_dict.values()), batch_relations, processed_raw_ids, source)

        self._update_all_product_counts()
        self.stdout.write(self.style.SUCCESS('\n‚úÖ FANZA/DMM ÂÖ®Â∑•Á®ã„ÅåÂÆå‰∫Ü„Åó„Åæ„Åó„Åü'))

    def _process_batch(self, products_data, relations_map, raw_ids, source):
        """ÂêçÂâçËß£Ê±∫„ÉªUPSERT„ÉªM2MÊõ¥Êñ∞„Çí‰∏ÄÊã¨ÂÆüË°å"""
        
        # 1. „Ç®„É≥„ÉÜ„Ç£„ÉÜ„Ç£Ëß£Ê±∫
        all_names = {M: set() for M in ENTITY_MODELS}
        for p in products_data:
            for M in [Maker, Label, Director, Series]:
                key = ENTITY_RELATION_KEYS[M]
                if p.get(key): all_names[M].add(p[key])
        
        for r in relations_map.values():
            for M in [Genre, Actress]:
                key = ENTITY_RELATION_KEYS[M]
                for name in r.get(key, []): all_names[M].add(name)

        pk_maps = {M: get_or_create_entity(M, list(names), source) for M, names in all_names.items() if names}

        # 2. FK„ÅÆÊõ∏„ÅçÊèõ„Åà„Å®„Ç§„É≥„Çπ„Çø„É≥„ÇπÂåñ
        upsert_list = []
        for p in products_data:
            p.pop('image_url', None) 
            p.pop('raw_data_id', None)
            
            for M in [Maker, Label, Director, Series]:
                key = ENTITY_RELATION_KEYS[M]
                name = p.pop(key, None)
                p[f'{key}_id'] = pk_maps.get(M, {}).get(name) if name else None
            
            upsert_list.append(AdultProduct(**p))

        # 3. „Éá„Éº„Çø„Éô„Éº„Çπ„Å∏ UPSERT
        with transaction.atomic():
            AdultProduct.objects.bulk_create(
                upsert_list,
                update_conflicts=True,
                unique_fields=['product_id_unique'],
                update_fields=[
                    'title', 'affiliate_url', 'image_url_list', 
                    'sample_movie_url', 'price', 'release_date', 
                    'maker_id', 'label_id', 'director_id', 'series_id', 'updated_at'
                ]
            )

            # M2MÂêåÊúü
            db_map = {obj.product_id_unique: obj.id for obj in AdultProduct.objects.filter(
                product_id_unique__in=[p.product_id_unique for p in upsert_list]
            )}

            for M in [Genre, Actress]:
                key = ENTITY_RELATION_KEYS[M]
                through_model = getattr(AdultProduct, key).through
                through_model.objects.filter(adultproduct_id__in=db_map.values()).delete()
                
                rels = []
                for unique_id, r in relations_map.items():
                    pid = db_map.get(unique_id)
                    m_map = pk_maps.get(M, {})
                    for name in r.get(key, []):
                        eid = m_map.get(name)
                        if pid and eid:
                            kwargs = {'adultproduct_id': pid, f'{M.__name__.lower()}_id': eid}
                            rels.append(through_model(**kwargs))
                
                if rels:
                    through_model.objects.bulk_create(rels, ignore_conflicts=True)

            RawApiData.objects.filter(id__in=raw_ids).update(migrated=True, updated_at=timezone.now())

    def _update_all_product_counts(self):
        """„Éû„Çπ„Çø„Éº„Éá„Éº„Çø„ÅÆ„Ç´„Ç¶„É≥„Éà‰∏ÄÊã¨Êõ¥Êñ∞"""
        self.stdout.write("‰ΩúÂìÅÊï∞„Ç´„Ç¶„É≥„Éà„ÇíÊõ¥Êñ∞‰∏≠...")
        with transaction.atomic():
            MAPPING = [
                (Actress, 'actresses'), (Genre, 'genres'),
                (Maker, 'maker_id'), (Label, 'label_id'),
                (Director, 'director_id'), (Series, 'series_id'),
            ]
            for Model, field in MAPPING:
                if field.endswith('_id'):
                    subq = AdultProduct.objects.filter(**{field: OuterRef('pk')}).values(field).annotate(c=Count('id')).values('c')[:1]
                else:
                    through = getattr(AdultProduct, field).through
                    fk = f"{Model.__name__.lower()}_id"
                    subq = through.objects.filter(**{fk: OuterRef('pk')}).values(fk).annotate(c=Count('adultproduct_id')).values('c')[:1]
                
                Model.objects.update(product_count=Coalesce(Subquery(subq, output_field=models.IntegerField()), 0))