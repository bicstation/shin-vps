# -*- coding: utf-8 -*-
import json
import logging
from datetime import datetime

from django.core.management.base import BaseCommand
from django.db import transaction
from django.db.models import Count
from django.utils import timezone
import traceback

# å…±é€šãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£
from api.utils.adult.fanza_normalizer import normalize_fanza_data
from api.utils.adult.entity_manager import get_or_create_entity 

from api.models import (
    RawApiData, AdultProduct, Genre, Actress, 
    Director, Maker, Label, Series
)

logger = logging.getLogger('normalize_adult')

ENTITY_MAP = {
    'maker': Maker, 
    'label': Label,
    'series': Series,
    'director': Director,
    'genre': Genre, 
    'actress': Actress,
}

class Command(BaseCommand):
    help = 'RawApiDataã‹ã‚‰AdultProductã¸ãƒ‡ãƒ¼ã‚¿ã‚’æ­£è¦åŒ–ã—ã¾ã™ï¼ˆFANZA/DMMä¸¡å¯¾å¿œï¼‰ã€‚'

    def add_arguments(self, parser):
        parser.add_argument(
            '--limit',
            type=int,
            help='å‡¦ç†ã™ã‚‹Rawãƒ¬ã‚³ãƒ¼ãƒ‰æ•°ã‚’åˆ¶é™ã—ã¾ã™ã€‚',
        )
        parser.add_argument(
            '--source',
            type=str,
            default=None,  # æŒ‡å®šãŒãªã„å ´åˆã¯å…¨ã‚½ãƒ¼ã‚¹ã‚’å¯¾è±¡ã«ã™ã‚‹
            help='æ­£è¦åŒ–å¯¾è±¡ã®ã‚½ãƒ¼ã‚¹ã‚’æŒ‡å®š (FANZA or DMM)',
        )

    def handle(self, *args, **options):
        # 1. å‡¦ç†å¯¾è±¡ã®ã‚½ãƒ¼ã‚¹ã‚’æ±ºå®š
        source_opt = options.get('source')
        if source_opt:
            sources_to_process = [source_opt.upper()]
        else:
            # ğŸ’¡ æŒ‡å®šãŒãªã„å ´åˆã¯è‡ªå‹•çš„ã«ä¸¡æ–¹ã‚’å‡¦ç†å¯¾è±¡ã«å«ã‚ã‚‹
            sources_to_process = ['FANZA', 'DMM']
        
        limit = options.get('limit')
        logging.getLogger('api_utils').setLevel(logging.DEBUG) 

        for current_source in sources_to_process:
            self.API_SOURCE = current_source
            self.stdout.write(self.style.NOTICE(f'\n--- {self.API_SOURCE} æ­£è¦åŒ–ãƒ•ã‚§ãƒ¼ã‚ºã‚’é–‹å§‹ã—ã¾ã™ ---'))

            # ğŸ’¡ æœªç§»è¡Œã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
            raw_data_qs = RawApiData.objects.filter(
                api_source=self.API_SOURCE, 
                migrated=False 
            ).order_by('-id')

            if limit:
                raw_data_qs = raw_data_qs[:limit]

            total_batches = raw_data_qs.count()
            if total_batches == 0:
                self.stdout.write(self.style.SUCCESS(f'{self.API_SOURCE} ã®æœªå‡¦ç†ãƒ¬ã‚³ãƒ¼ãƒ‰ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚'))
                continue

            self.stdout.write(self.style.NOTICE(f'å‡¦ç†å¯¾è±¡: {total_batches} ä»¶'))

            processed_count = 0
            for raw_instance in raw_data_qs:
                try:
                    with transaction.atomic():
                        # --- å·¥ç¨‹1: ãƒ‡ãƒ¼ã‚¿ã®æ­£è¦åŒ–ï¼ˆå…±é€šãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã¸ã®å¤‰æ›ï¼‰ ---
                        products_data_list, relations_data_list = normalize_fanza_data(raw_instance) 
                        
                        if not products_data_list:
                            raw_instance.migrated = True
                            raw_instance.save(update_fields=['migrated'])
                            continue

                        # --- å·¥ç¨‹2: ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ï¼ˆãƒ¡ãƒ¼ã‚«ãƒ¼ãƒ»å¥³å„ªç­‰ï¼‰ã®åŒæœŸ ---
                        entity_pk_maps = {}
                        all_entities = {
                            'Maker': set(), 'Label': set(), 'Director': set(), 
                            'Series': set(), 'Genre': set(), 'Actress': set()
                        }
                        
                        for p in products_data_list:
                            for k in ['maker', 'label', 'director', 'series']:
                                if p.get(k): all_entities[k.capitalize()].add(p[k])

                        for r in relations_data_list:
                            for g in r.get('genres', []): all_entities['Genre'].add(g)
                            for a in r.get('actresses', []): all_entities['Actress'].add(a)

                        for e_type, names in all_entities.items():
                            if names:
                                entity_pk_maps[e_type] = get_or_create_entity(
                                    model=ENTITY_MAP[e_type.lower()], 
                                    names=list(names), 
                                    api_source=self.API_SOURCE
                                )

                        # --- å·¥ç¨‹3: AdultProduct ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®æº–å‚™ ---
                        products_to_upsert = []
                        for p_data in products_data_list:
                            # ã‚½ãƒ¼ã‚¹æƒ…å ±ã‚’ä¸Šæ›¸ãï¼ˆDMMã®ç”Ÿãƒ‡ãƒ¼ã‚¿ãªã‚‰DMMã¨ã—ã¦ä¿å­˜ï¼‰
                            p_data['api_source'] = self.API_SOURCE
                            
                            # ãƒ¦ãƒ‹ãƒ¼ã‚¯IDã®ç”Ÿæˆï¼ˆDMM_xxx ã¾ãŸã¯ FANZA_xxxï¼‰
                            p_data['product_id_unique'] = f"{self.API_SOURCE}_{p_data['api_product_id']}"

                            # å¤–éƒ¨ã‚­ãƒ¼ï¼ˆIDï¼‰ã®å·®ã—æ›¿ãˆ
                            for k in ['maker', 'label', 'director', 'series']:
                                val = p_data.pop(k, None)
                                if val:
                                    p_data[f'{k}_id'] = entity_pk_maps.get(k.capitalize(), {}).get(val)
                            
                            products_to_upsert.append(AdultProduct(**p_data))

                        # --- å·¥ç¨‹4: ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã¸ã®ä¸€æ‹¬ä¿å­˜ (UPSERT) ---
                        AdultProduct.objects.bulk_create(
                            products_to_upsert,
                            update_conflicts=True,
                            unique_fields=['product_id_unique'],
                            update_fields=[
                                'raw_data_id', 'title', 'affiliate_url', 'image_url_list',
                                'release_date', 'price', 'maker_id', 'label_id', 'updated_at'
                            ],
                        )

                        # --- å·¥ç¨‹5: å¤šå¯¾å¤šãƒªãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆå¥³å„ªãƒ»ã‚¸ãƒ£ãƒ³ãƒ«ï¼‰ã®ç´ä»˜ã‘ ---
                        self._process_relations(relations_data_list, entity_pk_maps)

                        # --- å·¥ç¨‹6: ç”Ÿãƒ‡ãƒ¼ã‚¿å´ã®å®Œäº†ãƒ•ãƒ©ã‚°æ›´æ–° ---
                        raw_instance.migrated = True
                        raw_instance.updated_at = timezone.now()
                        raw_instance.save(update_fields=['migrated', 'updated_at'])
                        processed_count += 1

                except Exception as e:
                    self.stdout.write(self.style.ERROR(f"ID {raw_instance.id} ã§ã‚¨ãƒ©ãƒ¼: {str(e)}"))
                    logger.error(traceback.format_exc())
                    continue 

            self.stdout.write(self.style.SUCCESS(f'{self.API_SOURCE} æ­£è¦åŒ–å®Œäº†: {processed_count} ä»¶'))
        
        # ğŸ’¡ å…¨ã¦ã®ã‚½ãƒ¼ã‚¹ãŒå®Œäº†ã—ãŸå¾Œã«çµ±è¨ˆï¼ˆã‚«ã‚¦ãƒ³ãƒˆï¼‰ã‚’ä¸€æ‹¬æ›´æ–°
        self._update_all_product_counts()
        self.stdout.write(self.style.SUCCESS(f'\nâœ… ã™ã¹ã¦ã®ã‚½ãƒ¼ã‚¹ã®å·¥ç¨‹ãŒå®Œäº†ã—ã¾ã—ãŸ'))

    def _process_relations(self, relations_data_list, entity_pk_maps):
        """ä¸­é–“ãƒ†ãƒ¼ãƒ–ãƒ«ï¼ˆå¥³å„ªãƒ»ã‚¸ãƒ£ãƒ³ãƒ«ï¼‰ã®åŒæœŸãƒ­ã‚¸ãƒƒã‚¯"""
        for rel_data in relations_data_list:
            # ğŸ’¡ ç¾åœ¨ã®å‡¦ç†ã‚½ãƒ¼ã‚¹ã«åŸºã¥ã„ãŸä¸€æ„ã®IDã§è£½å“ã‚’ç‰¹å®š
            unique_id = f"{self.API_SOURCE}_{rel_data.get('api_product_id')}"
            try:
                product = AdultProduct.objects.get(product_id_unique=unique_id)
                
                # å¥³å„ªã®ç´ä»˜ã‘
                if 'actresses' in rel_data:
                    act_map = entity_pk_maps.get('Actress', {})
                    actress_ids = [act_map.get(name) for name in rel_data['actresses'] if act_map.get(name)]
                    product.actresses.set(actress_ids)
                
                # ã‚¸ãƒ£ãƒ³ãƒ«ã®ç´ä»˜ã‘
                if 'genres' in rel_data:
                    gen_map = entity_pk_maps.get('Genre', {})
                    genre_ids = [gen_map.get(name) for name in rel_data['genres'] if gen_map.get(name)]
                    product.genres.set(genre_ids)
                    
            except AdultProduct.DoesNotExist:
                continue

    def _update_all_product_counts(self):
        """ãƒã‚¹ã‚¿ãƒ¼ãƒ‡ãƒ¼ã‚¿ã® product_count ã‚’ä¸€æ‹¬é›†è¨ˆã—ã¦æ›´æ–°"""
        self.stdout.write("ãƒã‚¹ã‚¿ãƒ¼ãƒ‡ãƒ¼ã‚¿ã®ä½œå“æ•°ã‚’é›†è¨ˆä¸­...")

        targets = [
            (Maker, 'maker_id'),
            (Label, 'label_id'),
            (Director, 'director_id'),
            (Series, 'series_id'),
            (Genre, 'genres'),
            (Actress, 'actresses')
        ]

        for model, field_name in targets:
            self.stdout.write(f"é›†è¨ˆä¸­: {model.__name__}...")

            counts_query = AdultProduct.objects.values(field_name).annotate(total=Count('id'))
            count_map = {item[field_name]: item['total'] for item in counts_query if item[field_name]}

            all_objs = model.objects.all()
            updates = []

            for obj in all_objs:
                new_count = count_map.get(obj.id, 0)
                if obj.product_count != new_count:
                    obj.product_count = new_count
                    updates.append(obj)
            
            if updates:
                model.objects.bulk_update(updates, ['product_count'], batch_size=500)

        self.stdout.write(self.style.SUCCESS("ä½œå“æ•°ã®æ›´æ–°ãŒå®Œäº†ã—ã¾ã—ãŸã€‚"))