import os
import re
import ftplib
import gzip
import csv
import logging
from datetime import datetime
from typing import List, Dict, Any, Optional

from django.core.management.base import BaseCommand
from django.db import transaction
from django.utils import timezone
from api.models import PCProduct

# ãƒ­ã‚¬ãƒ¼è¨­å®š
logger = logging.getLogger(__name__)

class Command(BaseCommand):
    help = 'Dell FTP (MID:2557) ã‹ã‚‰è£½å“ã‚’å–å¾—ã—ã€PCProductã«ä¿å­˜ã—ã¾ã™ï¼ˆå…¨ä»¶ãƒ»ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰è§£æç‰ˆï¼‰'

    # --- è¨­å®šå®šæ•° ---
    FTP_HOST = "aftp.linksynergy.com"
    FTP_USER = os.getenv("LINKSHARE_BC_USER", "rkp_3273700")
    FTP_PASS = os.getenv("LINKSHARE_BC_PASS", "5OqF1NfuruvJlmuJXKQDRuzh")
    DOWNLOAD_DIR = "/tmp/dell_ftp_import"
    DELL_MID = "2557"
    SID = "3273700"

    def handle(self, *args, **options):
        self.stdout.write(self.style.SUCCESS(f"--- Dell FTP Import Start ({datetime.now()}) ---"))
        
        # æº–å‚™
        if not os.path.exists(self.DOWNLOAD_DIR):
            os.makedirs(self.DOWNLOAD_DIR)
        
        # FTPæ¥ç¶š
        ftp = self._connect_ftp()
        if not ftp:
            return

        try:
            target_filename = f"{self.DELL_MID}_{self.SID}_mp.txt.gz"
            local_gz_path = os.path.join(self.DOWNLOAD_DIR, target_filename)
            local_txt_path = local_gz_path.replace('.gz', '.txt')

            # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
            self.stdout.write(f"ğŸ“¡ Downloading: {target_filename}")
            with open(local_gz_path, 'wb') as f:
                ftp.retrbinary(f'RETR {target_filename}', f.write)

            # è§£å‡
            self.stdout.write("ğŸ”“ Decompressing...")
            with gzip.open(local_gz_path, 'rb') as f_in:
                with open(local_txt_path, 'wb') as f_out:
                    f_out.write(f_in.read())

            # è§£æã¨ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
            self._parse_and_import(local_txt_path)
            self.stdout.write(self.style.SUCCESS("âœ… Dell All-Product Import Completed."))

        except Exception as e:
            self.stderr.write(self.style.ERROR(f"âŒ Error: {str(e)}"))
        finally:
            # ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
            if os.path.exists(local_gz_path): os.remove(local_gz_path)
            if os.path.exists(local_txt_path): os.remove(local_txt_path)
            ftp.quit()

    def _parse_and_import(self, file_path: str):
        batch = []
        with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
            reader = csv.reader(f, delimiter='|')
            
            try:
                next(reader) # HDRè¡Œã‚’ã‚¹ã‚­ãƒƒãƒ—
            except StopIteration:
                return

            for row in reader:
                # æœ€å°é™ã®ã‚«ãƒ©ãƒ ãƒã‚§ãƒƒã‚¯ã¨ãƒ•ãƒƒã‚¿ãƒ¼è¡Œ(TRL)ã®å›é¿
                if not row or row[0] == 'TRL' or len(row) < 18:
                    continue

                name = row[1].strip()
                sku = row[2].strip()
                category_path = row[17].strip()

                # --- 1. ä¾¡æ ¼ã®å–å¾— (C14 = index 13) ---
                price_val = self._clean_price(row[13])

                # --- 2. ç”Ÿã®èª¬æ˜æ–‡ã®å–å¾— (C10 ã¾ãŸã¯ C11) ---
                raw_description = row[9].strip() or row[10].strip() or ""

                # --- 3. ã‚¹ãƒšãƒƒã‚¯æŠ½å‡º (å•†å“åã¨èª¬æ˜æ–‡ã‹ã‚‰) ---
                specs = self._extract_specs(name, raw_description)
                
                parts = []
                if specs['cpu']: parts.append(specs['cpu'])
                if specs['gpu']: parts.append(specs['gpu'])
                if specs['ram']: parts.append(f"{specs['ram']}GB RAM")
                if specs['ssd']: 
                    cap = specs['ssd']
                    s_str = f"{cap/1024}TB" if cap >= 1024 else f"{cap}GB"
                    parts.append(f"{s_str} SSD")
                
                # --- 4. descriptionã‚«ãƒ©ãƒ ã®æ§‹ç¯‰ (è§£æçµæœ + ç”Ÿãƒ†ã‚­ã‚¹ãƒˆ) ---
                if parts:
                    parsed_str = " / ".join(parts)
                    # ã‚¹ãƒšãƒƒã‚¯ãŒåˆ¤æ˜ã—ãŸå ´åˆã¯ã€Œã‚¹ãƒšãƒƒã‚¯ / å…¬å¼èª¬æ˜ã€ã®å½¢å¼ã«ã™ã‚‹
                    full_description = f"{parsed_str} / {raw_description}"
                else:
                    # åˆ¤æ˜ã—ãªã„å ´åˆã¯ç”Ÿãƒ‡ãƒ¼ã‚¿ã‚’ãã®ã¾ã¾ä¿æŒ
                    full_description = raw_description

                # --- 5. ã‚¸ãƒ£ãƒ³ãƒ«ã®è‡ªå‹•åˆ¤å®š (ãƒãƒ‹ã‚¢å‘ã‘åˆ†é¡) ---
                unified_genre = "PC"
                if "PowerEdge" in name or "ã‚µãƒ¼ãƒãƒ¼" in category_path:
                    unified_genre = "Server"
                elif "ãƒ¢ãƒ‹ã‚¿ãƒ¼" in category_path or "Monitor" in name:
                    unified_genre = "Monitor"
                elif "ãƒãƒ¼ãƒˆ" in category_path or "Laptop" in category_path:
                    unified_genre = "Laptop"

                # --- 6. ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ç”Ÿæˆ ---
                product = PCProduct(
                    unique_id=f"dell_{sku}",
                    site_prefix="dell",
                    maker="Dell",
                    name=name,
                    price=price_val,
                    url=row[8].strip(),
                    image_url=row[6].strip(),
                    affiliate_url=row[5].strip(),
                    description=full_description,
                    raw_genre=category_path,
                    unified_genre=unified_genre,
                    stock_status=row[23].strip() if len(row) > 23 else "åœ¨åº«ã‚ã‚Š",
                    is_active=True,
                    updated_at=timezone.now()
                )
                batch.append(product)

                # 100ä»¶ã”ã¨ã«ãƒãƒ«ã‚¯å‡¦ç†
                if len(batch) >= 100:
                    self._bulk_upsert(batch)
                    batch = []

            if batch:
                self._bulk_upsert(batch)

    def _extract_specs(self, name: str, desc: str) -> Dict[str, Any]:
        """å•†å“åã¨èª¬æ˜æ–‡ã‹ã‚‰ä¸»è¦ã‚¹ãƒšãƒƒã‚¯ã‚’æŠœãå‡ºã™æ­£è¦è¡¨ç¾"""
        text = f"{name} {desc}"
        
        # CPU: Core i/Ryzen/Ultra/Snapdragon/Xeon(ã‚µãƒ¼ãƒãƒ¼ç”¨)
        cpu = re.search(r'(Core\s?i[3579]|Ryzen\s?[3579]|Ultra\s?\d|Snapdragon|Xeon|Celeron|Pentium)', text, re.I)
        # GPU: RTX/GTX/Radeon/Iris/Graphics
        gpu = re.search(r'(RTX\s?\d{4}|GTX\s?\d{4}|Radeon|Iris\s?Xe|Graphics)', text, re.I)
        # RAM: ã€Œ16GBã€ãªã©ã‚’æŠ½å‡º
        ram = re.search(r'(\d+)\s?GB\s?(?:RAM|ãƒ¡ãƒ¢ãƒª|DDR)', text, re.I)
        # SSD/HDD: å®¹é‡ã‚’TB/GBã§æŠ½å‡º
        ssd = re.search(r'(\d+)\s?(GB|TB)\s?(?:SSD|NVMe|ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸|HDD)', text, re.I)

        ssd_val = 0
        if ssd:
            try:
                v = int(ssd.group(1))
                ssd_val = v * 1024 if ssd.group(2).upper() == 'TB' else v
            except:
                pass

        return {
            'cpu': cpu.group(1) if cpu else None,
            'gpu': gpu.group(1) if gpu else None,
            'ram': int(ram.group(1)) if ram else 0,
            'ssd': ssd_val
        }

    def _clean_price(self, p_str: str) -> int:
        """ä¾¡æ ¼æ–‡å­—åˆ—ã‹ã‚‰æ•°å€¤ã®ã¿ã‚’æŠ½å‡ºã—ã¦æ•´æ•°åŒ–"""
        try:
            nums = re.sub(r'[^\d.]', '', p_str)
            return int(float(nums))
        except (ValueError, TypeError):
            return 0

    def _bulk_upsert(self, batch: List[PCProduct]):
        """unique_idã‚’ãƒ•ãƒƒã‚¯ã«æ›´æ–°ã¾ãŸã¯ä½œæˆ"""
        with transaction.atomic():
            for item in batch:
                PCProduct.objects.update_or_create(
                    unique_id=item.unique_id,
                    defaults={
                        'site_prefix': item.site_prefix,
                        'maker': item.maker,
                        'name': item.name,
                        'price': item.price,
                        'url': item.url,
                        'image_url': item.image_url,
                        'affiliate_url': item.affiliate_url,
                        'description': item.description,
                        'raw_genre': item.raw_genre,
                        'unified_genre': item.unified_genre,
                        'stock_status': item.stock_status,
                        'is_active': item.is_active,
                        'updated_at': item.updated_at,
                    }
                )

    def _connect_ftp(self) -> Optional[ftplib.FTP]:
        """FTPæ¥ç¶šã¨ãƒ­ã‚°ã‚¤ãƒ³"""
        try:
            ftp = ftplib.FTP(self.FTP_HOST, timeout=60)
            ftp.login(self.FTP_USER, self.FTP_PASS)
            ftp.set_pasv(True)
            return ftp
        except Exception as e:
            self.stderr.write(self.style.ERROR(f"FTP Connection Fail: {e}"))
            return None