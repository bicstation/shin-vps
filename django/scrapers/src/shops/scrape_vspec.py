import os
import django
import requests
from bs4 import BeautifulSoup
import hashlib
import time
import re
import urllib.parse

# --- Djangoè¨­å®š ---
os.environ["DJANGO_ALLOW_ASYNC_UNSAFE"] = "true"
os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'tiper_api.settings')
django.setup()
from api.models.pc_products import PCProduct

MAKER_NAME = "vspec"
SITE_PREFIX = "VSPEC"
AFFILIATE_BASE_URL = "https://ck.jp.ap.valuecommerce.com/servlet/referral?sid=3697471&pid=892466407&vc_url="

def run_vspec_crawler():
    target_urls = [
        "https://vspec-bto.com/bto/bto-game.htm",
        "https://vspec-bto.com/bto/bto-hi.htm",
        "https://vspec-bto.com/bto/bto-light.htm",
        "https://vspec-bto.com/bto/bto-minimal-pc.htm",
        "https://vspec-bto.com/bto/bto-Coreultra-1851-pc.htm",
        "https://vspec-bto.com/bto/bto-ryzen-pc.htm"
    ]
    
    headers = {"User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"}

    print(f"\nğŸš€ {SITE_PREFIX} ã€ã‚¹ãƒšãƒƒã‚¯é«˜ç²¾åº¦ãƒ»æŠ½å‡ºãƒ¢ãƒ¼ãƒ‰ã€‘å®Ÿè¡Œä¸­...")
    total_saved = 0

    for cat_url in target_urls:
        try:
            print(f"\nğŸ“¡ ã‚«ãƒ†ã‚´ãƒªè§£æ: {cat_url}")
            res = requests.get(cat_url, headers=headers, timeout=30)
            res.encoding = 'shift_jis'
            soup = BeautifulSoup(res.text, 'html.parser')
            
            links = soup.find_all('a', href=re.compile(r'system_detail\.html'))
            product_urls = sorted(list(set([urllib.parse.urljoin(cat_url, a.get('href')) for a in links])))

            for p_url in product_urls:
                try:
                    time.sleep(1.0)
                    p_res = requests.get(p_url, headers=headers, timeout=30)
                    p_res.encoding = 'shift_jis'
                    p_soup = BeautifulSoup(p_res.text, 'html.parser')

                    # å•†å“åå–å¾—
                    name_el = p_soup.select_one('.sys-name-1col, h2, .sys-name')
                    name = name_el.get_text(strip=True) if name_el else "VSPEC BTO PC"
                    
                    # ä¾¡æ ¼å–å¾—
                    price = 0
                    price_targets = p_soup.select('.price, .sys-price, b, .sys-price-1col')
                    for target in price_targets:
                        text = target.get_text(strip=True)
                        if any(x in text for x in ['å††', 'ï¿¥', '\\']):
                            val = re.sub(r'\D', '', text)
                            if val and int(val) > 1000:
                                price = int(val)
                                break

                    # ç”»åƒå–å¾—
                    image_url = ""
                    img_el = p_soup.select_one('.sys-image img, #main_img, a[rel^="lightbox"] img')
                    if img_el:
                        image_url = urllib.parse.urljoin(p_url, img_el.get('src'))

                    # --- âš™ ã‚¹ãƒšãƒƒã‚¯æŠ½å‡ºãƒ­ã‚¸ãƒƒã‚¯å¼·åŒ– ---
                    spec_data = {"CPU": "æœªç¢ºèª", "GPU": "æ¨™æº–æ§‹æˆ", "MEM": "æ¨™æº–æ­è¼‰", "SSD": "æ¨™æº–æ­è¼‰"}
                    
                    rows = p_soup.find_all('tr')
                    for row in rows:
                        cells = row.find_all(['td', 'th'])
                        if len(cells) >= 2:
                            label = cells[0].get_text(strip=True)
                            val = cells[1].get_text(strip=True)
                            
                            # ãƒ©ãƒ™ãƒ«ã«ç‰¹å®šã®å˜èªãŒå«ã¾ã‚Œã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯ (ã‹ã¤ã€å€¤ãŒç©ºã‚„ã€Œç„¡ã—ã€ã§ãªã„)
                            if val and val != "ç„¡ã—" and "é¸æŠã—ã¦ä¸‹ã•ã„" not in val:
                                if "CPU" in label.upper() and "ãƒ•ã‚¡ãƒ³" not in label and "ã‚¯ãƒ¼ãƒ©ãƒ¼" not in label:
                                    spec_data["CPU"] = val
                                elif any(x in label for x in ["ãƒ“ãƒ‡ã‚ª", "ã‚°ãƒ©ãƒ•ã‚£ãƒƒã‚¯", "GPU"]):
                                    spec_data["GPU"] = val
                                elif "ãƒ¡ãƒ¢ãƒª" in label:
                                    spec_data["MEM"] = val
                                elif any(x in label for x in ["SSD", "ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸", "HDD"]):
                                    spec_data["SSD"] = val

                    spec_summary = f"{spec_data['CPU']} / {spec_data['GPU']} / {spec_data['MEM']} / {spec_data['SSD']}"

                    # ğŸ”Š ã‚³ãƒ³ã‚½ãƒ¼ãƒ«å®Ÿæ³
                    print(f"ğŸ’ [è§£æ] {name[:30]}...")
                    print(f"   ğŸ–¼ ç”»åƒ: {image_url}")
                    print(f"   âš™ ã‚¹ãƒšãƒƒã‚¯: {spec_summary}")
                    print(f"   ğŸ’° ä¾¡æ ¼: {price:,}å††")
                    print("-" * 30)

                    # ä¿å­˜å‡¦ç†
                    encoded_url = urllib.parse.quote(p_url, safe='')
                    aff_url = f"{AFFILIATE_BASE_URL}{encoded_url}"
                    uid = "vspec-v8-" + hashlib.md5(p_url.encode()).hexdigest()[:12]

                    PCProduct.objects.update_or_create(
                        unique_id=uid,
                        defaults={
                            'site_prefix': SITE_PREFIX, 'maker': MAKER_NAME,
                            'name': name, 'price': price, 'url': p_url,
                            'affiliate_url': aff_url, 'image_url': image_url,
                            'description': spec_summary,
                            'is_active': True, 'stock_status': "åœ¨åº«ã‚ã‚Š",
                            'raw_genre': 'bto-pc',
                        }
                    )
                    total_saved += 1
                except: continue

        except Exception as e: print(f"âŒ ã‚¨ãƒ©ãƒ¼: {e}")

    print(f"\nâœ¨ å®Œäº†ï¼ åˆè¨ˆ {total_saved} ä»¶ã‚’ã€Œæœ¬ç‰©ã®ã‚¹ãƒšãƒƒã‚¯ã€ã§ä¿å­˜ã—ã¾ã—ãŸã€‚")

if __name__ == "__main__":
    run_vspec_crawler()