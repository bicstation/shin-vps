import os
import re
import ftplib
import gzip
import csv
import logging
from datetime import datetime
from typing import List, Dict, Any, Optional

from django.core.management.base import BaseCommand
from django.db import transaction
from django.utils import timezone
from api.models import PCProduct

# ãƒ­ã‚¬ãƒ¼è¨­å®š
logger = logging.getLogger(__name__)

class Command(BaseCommand):
    help = 'LinkShare FTPã‹ã‚‰è£½å“ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã—ã€PCProductãƒ¢ãƒ‡ãƒ«ã‚’æ›´æ–°ã—ã¾ã™ï¼ˆDell/ASUSå¯¾å¿œç‰ˆï¼‰'

    # --- è¨­å®šå®šæ•° ---
    FTP_HOST = "aftp.linksynergy.com"
    FTP_USER = os.getenv("LINKSHARE_BC_USER", "rkp_3273700")
    FTP_PASS = os.getenv("LINKSHARE_BC_PASS", "5OqF1NfuruvJlmuJXKQDRuzh")
    DOWNLOAD_DIR = "/tmp/pc_ftp_import"
    SID = "3273700"  # å…±é€šã®SID

    def add_arguments(self, parser):
        # å®Ÿè¡Œæ™‚ã«MIDã‚’æŒ‡å®šã§ãã‚‹ã‚ˆã†ã«ã™ã‚‹
        parser.add_argument('--mid', type=str, help='Merchant ID (Dell:2557, ASUS:437088)', default='2557')

    def handle(self, *args, **options):
        target_mid = options['mid']
        # ã‚µã‚¤ãƒˆåã¨ãƒ¡ãƒ¼ã‚«ãƒ¼åã‚’MIDã‹ã‚‰åˆ¤å®š
        site_info = {
            "2557": {"prefix": "dell", "maker": "Dell"},
            "437088": {"prefix": "asus", "maker": "ASUS"}
        }.get(target_mid, {"prefix": "etc", "maker": "Unknown"})

        self.stdout.write(self.style.SUCCESS(f"ğŸš€ --- {site_info['maker']} FTP Import Start ({datetime.now()}) ---"))
        
        # ä¿å­˜å…ˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæº–å‚™
        if not os.path.exists(self.DOWNLOAD_DIR):
            os.makedirs(self.DOWNLOAD_DIR)
        
        # FTPæ¥ç¶š
        ftp = self._connect_ftp()
        if not ftp:
            return

        try:
            # ãƒ•ã‚¡ã‚¤ãƒ«åã®æ±ºå®šï¼ˆä¾‹: 437088_3273700_mp.txt.gzï¼‰
            target_filename = f"{target_mid}_{self.SID}_mp.txt.gz"
            local_gz_path = os.path.join(self.DOWNLOAD_DIR, target_filename)
            local_txt_path = local_gz_path.replace('.gz', '.txt')

            # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å®Ÿè¡Œ
            self.stdout.write(f"ğŸ“¡ Downloading: {target_filename}")
            with open(local_gz_path, 'wb') as f:
                ftp.retrbinary(f'RETR {target_filename}', f.write)

            # è§£å‡å‡¦ç†
            self.stdout.write("ğŸ”“ Decompressing...")
            with gzip.open(local_gz_path, 'rb') as f_in:
                with open(local_txt_path, 'wb') as f_out:
                    f_out.write(f_in.read())

            # è§£æã¨ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
            self._parse_and_import(local_txt_path, target_mid, site_info)
            self.stdout.write(self.style.SUCCESS(f"âœ… {site_info['maker']} Import Completed."))

        except Exception as e:
            self.stderr.write(self.style.ERROR(f"âŒ Error during processing: {str(e)}"))
        finally:
            # ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
            if os.path.exists(local_gz_path): os.remove(local_gz_path)
            if os.path.exists(local_txt_path): os.remove(local_txt_path)
            if ftp: ftp.quit()

    def _parse_and_import(self, file_path: str, mid: str, site_info: dict):
        batch = []
        with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
            reader = csv.reader(f, delimiter='|')
            
            try:
                next(reader)  # HDRï¼ˆãƒ˜ãƒƒãƒ€ãƒ¼ï¼‰è¡Œã‚’ã‚¹ã‚­ãƒƒãƒ—
            except StopIteration:
                return

            for row in reader:
                # æœ€å°é™ã®ã‚«ãƒ©ãƒ ãƒã‚§ãƒƒã‚¯ã¨ãƒ•ãƒƒã‚¿ãƒ¼è¡Œ(TRL)ã®å›é¿
                if not row or row[0] == 'TRL' or len(row) < 18:
                    continue

                sku = row[2].strip()
                name = row[1].strip()
                category_path = row[17].strip()

                # 1. ä¾¡æ ¼ã®å–å¾— (C14 = index 13)
                price_val = self._clean_price(row[13])

                # 2. èª¬æ˜æ–‡ã®å–å¾— (C10 ã¾ãŸã¯ C11)
                raw_description = row[9].strip() or row[10].strip() or ""

                # 3. ã‚¹ãƒšãƒƒã‚¯æŠ½å‡ºï¼ˆæ­£è¦è¡¨ç¾ãƒ­ã‚¸ãƒƒã‚¯ï¼‰
                specs = self._extract_specs(name, raw_description)
                
                parts = []
                if specs['cpu']: parts.append(specs['cpu'])
                if specs['gpu']: parts.append(specs['gpu'])
                if specs['ram']: parts.append(f"{specs['ram']}GB RAM")
                if specs['ssd']: 
                    cap = specs['ssd']
                    s_str = f"{cap/1024}TB" if cap >= 1024 else f"{cap}GB"
                    parts.append(f"{s_str} SSD")
                
                # 4. descriptionã‚«ãƒ©ãƒ ã®æ§‹ç¯‰
                if parts:
                    parsed_str = " / ".join(parts)
                    full_description = f"{parsed_str} / {raw_description}"
                else:
                    full_description = raw_description

                # 5. ã‚¸ãƒ£ãƒ³ãƒ«ã®è‡ªå‹•åˆ¤å®š
                unified_genre = "PC"
                if any(x in name for x in ["PowerEdge", "ã‚µãƒ¼ãƒãƒ¼"]) or "Server" in category_path:
                    unified_genre = "Server"
                elif any(x in name for x in ["Monitor", "ãƒ¢ãƒ‹ã‚¿ãƒ¼"]) or "Monitor" in category_path:
                    unified_genre = "Monitor"
                elif any(x in category_path for x in ["ãƒãƒ¼ãƒˆ", "Laptop", "Laptop"]):
                    unified_genre = "Laptop"

                # 6. ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ç”Ÿæˆ
                product = PCProduct(
                    unique_id=f"{site_info['prefix']}_{sku}",
                    site_prefix=site_info['prefix'],
                    maker=site_info['maker'],
                    name=name,
                    price=price_val,
                    url=row[8].strip(),
                    image_url=row[6].strip(),
                    affiliate_url=row[5].strip(),
                    description=full_description,
                    raw_genre=category_path,
                    unified_genre=unified_genre,
                    stock_status=row[23].strip() if len(row) > 23 else "åœ¨åº«ã‚ã‚Š",
                    is_active=True,
                    updated_at=timezone.now()
                )
                batch.append(product)

                # 100ä»¶ã”ã¨ã«ãƒãƒ«ã‚¯ã‚¢ãƒƒãƒ—ã‚µãƒ¼ãƒˆ
                if len(batch) >= 100:
                    self._bulk_upsert(batch)
                    batch = []

            if batch:
                self._bulk_upsert(batch)

    def _extract_specs(self, name: str, desc: str) -> Dict[str, Any]:
        """å•†å“åã¨èª¬æ˜æ–‡ã‹ã‚‰ã‚¹ãƒšãƒƒã‚¯æƒ…å ±ã‚’æŠ½å‡º"""
        text = f"{name} {desc}"
        cpu = re.search(r'(Core\s?i[3579]|Ryzen\s?[3579]|Ultra\s?\d|Snapdragon|Xeon|Celeron|Pentium)', text, re.I)
        gpu = re.search(r'(RTX\s?\d{4}|GTX\s?\d{4}|Radeon|Iris\s?Xe|Graphics)', text, re.I)
        ram = re.search(r'(\d+)\s?GB\s?(?:RAM|ãƒ¡ãƒ¢ãƒª|DDR)', text, re.I)
        ssd = re.search(r'(\d+)\s?(GB|TB)\s?(?:SSD|NVMe|ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸|HDD)', text, re.I)

        ssd_val = 0
        if ssd:
            try:
                v = int(ssd.group(1))
                ssd_val = v * 1024 if ssd.group(2).upper() == 'TB' else v
            except: pass

        return {
            'cpu': cpu.group(1) if cpu else None,
            'gpu': gpu.group(1) if gpu else None,
            'ram': int(ram.group(1)) if ram else 0,
            'ssd': ssd_val
        }

    def _clean_price(self, p_str: str) -> int:
        """ä¾¡æ ¼æ–‡å­—åˆ—ã‚’æ•°å€¤åŒ–"""
        try:
            nums = re.sub(r'[^\d.]', '', p_str)
            return int(float(nums))
        except (ValueError, TypeError):
            return 0

    def _bulk_upsert(self, batch: List[PCProduct]):
        """Djangoã®update_or_createã§ãƒãƒ«ã‚¯æ›´æ–°"""
        with transaction.atomic():
            for item in batch:
                PCProduct.objects.update_or_create(
                    unique_id=item.unique_id,
                    defaults={
                        'site_prefix': item.site_prefix,
                        'maker': item.maker,
                        'name': item.name,
                        'price': item.price,
                        'url': item.url,
                        'image_url': item.image_url,
                        'affiliate_url': item.affiliate_url,
                        'description': item.description,
                        'raw_genre': item.raw_genre,
                        'unified_genre': item.unified_genre,
                        'stock_status': item.stock_status,
                        'is_active': item.is_active,
                        'updated_at': item.updated_at,
                    }
                )

    def _connect_ftp(self) -> Optional[ftplib.FTP]:
        """FTPæ¥ç¶š"""
        try:
            ftp = ftplib.FTP(self.FTP_HOST, timeout=60)
            ftp.login(self.FTP_USER, self.FTP_PASS)
            ftp.set_pasv(True)
            return ftp
        except Exception as e:
            self.stderr.write(self.style.ERROR(f"âŒ FTP Connection Fail: {e}"))
            return None