# -*- coding: utf-8 -*-
import logging
import json
import re
from django.core.management.base import BaseCommand
from django.db import transaction, models
from django.db.models import F, Count, OuterRef, Subquery
from django.db.models.functions import Coalesce
from django.utils import timezone 

# é–¢é€£ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ã®ãƒ¢ãƒ‡ãƒ«ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from api.models import RawApiData, AdultProduct, Genre, Actress, Maker, Label, Director, Series

# ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from api.utils.common import generate_product_unique_id 
from api.utils.adult.duga_normalizer import normalize_duga_data 
from api.utils.adult.entity_manager import get_or_create_entity 

logger = logging.getLogger(__name__)

# ã™ã¹ã¦ã®ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ãƒ¢ãƒ‡ãƒ«ã‚’ãƒªã‚¹ãƒˆåŒ–
ENTITY_MODELS = [Maker, Label, Director, Series, Genre, Actress]
ENTITY_RELATION_KEYS = {
    Maker: 'maker', 
    Label: 'label', 
    Director: 'director', 
    Series: 'series',
    Genre: 'genres', 
    Actress: 'actresses'
}

class Command(BaseCommand):
    help = 'RawApiData (DUGA) ã‚’èª­ã¿è¾¼ã¿ã€ç”»åƒã‚’æœ€é«˜ç”»è³ªåŒ–ã—ã¦AdultProductãƒ¢ãƒ‡ãƒ«ã«æ­£è¦åŒ–ä¿å­˜ã—ã¾ã™ã€‚'
    API_SOURCE = 'DUGA'

    def _optimize_url(self, url):
        """ç”»åƒURLã‚’é«˜ç”»è³ªç‰ˆã«ç½®æ›ã™ã‚‹å…±é€šå†…éƒ¨é–¢æ•°"""
        if not url:
            return ""
        if url.startswith('//'):
            url = 'https:' + url
            
        if 'pics.dmm.com' in url or 'pics.dmm.co.jp' in url:
            # p[s|t].jpg -> pl.jpg
            url = re.sub(r'p[s|t]\.jpg', 'pl.jpg', url, flags=re.IGNORECASE)
            # _[m|s].jpg -> _l.jpg
            url = re.sub(r'_[ms]\.jpg', '_l.jpg', url, flags=re.IGNORECASE)
        return url

    def _resolve_entity_names_to_pks(self, product_list, relations_map):
        """ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£åã‚’PKã«è§£æ±ºã—ã€è¾æ›¸ã®ã‚­ãƒ¼ã‚’ _id ã«æ›¸ãæ›ãˆã‚‹"""
        all_entity_names = {Model: set() for Model in ENTITY_MODELS}

        # 1. ã™ã¹ã¦ã®ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£åã‚’åé›†
        for p in product_list:
            for Model in [Maker, Label, Director, Series]:
                key = ENTITY_RELATION_KEYS[Model]
                name = p.get(key)
                if name:
                    all_entity_names[Model].add(name)

            raw_id = p.get('raw_data_id')
            relations = relations_map.get(raw_id)
            if relations:
                for Model in [Genre, Actress]:
                    key = ENTITY_RELATION_KEYS[Model]
                    names = relations.get(key, [])
                    all_entity_names[Model].update(names)

        # 2. PK ã‚’ä¸€æ‹¬å–å¾—
        pk_maps = {Model: get_or_create_entity(Model, list(names), self.API_SOURCE) 
                   for Model, names in all_entity_names.items() if names}

        # 3. è¾æ›¸å†…ã®ã‚­ãƒ¼ã‚’æ›¸ãæ›ãˆ
        for p in product_list:
            for Model in [Maker, Label, Director, Series]:
                key = ENTITY_RELATION_KEYS[Model]
                name = p.pop(key, None)
                p[f'{key}_id'] = pk_maps.get(Model, {}).get(name) if name else None

            raw_id = p.get('raw_data_id')
            relations = relations_map.get(raw_id)
            if relations:
                for Model in [Genre, Actress]:
                    key = ENTITY_RELATION_KEYS[Model]
                    names = relations.pop(key, [])
                    # è§£æ±ºã§ããŸPKã®ã¿ä¿æŒ
                    pks = [pk_maps.get(Model, {}).get(n) for n in names if pk_maps.get(Model, {}).get(n)]
                    relations[f'{key}_ids'] = pks

    def handle(self, *args, **options):
        self.stdout.write(self.style.NOTICE(f'--- {self.API_SOURCE} æ­£è¦åŒ–ãƒ»é«˜ç”»è³ªåŒ–å‡¦ç†é–‹å§‹ ---'))

        raw_data_qs = RawApiData.objects.filter(api_source=self.API_SOURCE, migrated=False).order_by('id')
        total_count = raw_data_qs.count()
        
        if total_count == 0:
            self.stdout.write(self.style.SUCCESS("æœªå‡¦ç†ã®Rawãƒ‡ãƒ¼ã‚¿ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚"))
            return

        products_data = [] 
        relations_map = {} 
        processed_raw_ids = []
        batch_size = 500
        
        for raw_instance in raw_data_qs:
            try:
                normalized_data_list, relations_list = normalize_duga_data(raw_instance)
                if not normalized_data_list:
                    continue
                    
                product_data = normalized_data_list[0]
                relations = relations_list[0]
                
                # ğŸš€ ç”»åƒURLãƒªã‚¹ãƒˆã‚’é«˜ç”»è³ªåŒ–ãƒ»é‡è¤‡æ’é™¤
                if 'image_url_list' in product_data:
                    optimized_images = [self._optimize_url(u) for u in product_data['image_url_list']]
                    product_data['image_url_list'] = list(dict.fromkeys(filter(None, optimized_images)))

                # ğŸ¥ å‹•ç”»ãƒ‡ãƒ¼ã‚¿ã®ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ç”»åƒã‚‚é«˜ç”»è³ªåŒ–
                if isinstance(product_data.get('sample_movie_url'), dict):
                    preview = product_data['sample_movie_url'].get('preview_image')
                    if preview:
                        product_data['sample_movie_url']['preview_image'] = self._optimize_url(preview)

                # âš ï¸ ãƒ¢ãƒ‡ãƒ«ã«å­˜åœ¨ã—ãªã„ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’ç¢ºå®Ÿã«å‰Šé™¤
                product_data.pop('image_url', None)

                product_data['updated_at'] = timezone.now()
                products_data.append(product_data) 
                relations_map[raw_instance.id] = relations
                processed_raw_ids.append(raw_instance.id)
                
                if len(products_data) >= batch_size:
                    self._process_batch(products_data, relations_map, processed_raw_ids)
                    products_data, relations_map, processed_raw_ids = [], {}, []
                    
            except Exception as e:
                logger.error(f"Raw ID {raw_instance.id} å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")

        if products_data:
            self._process_batch(products_data, relations_map, processed_raw_ids)

        self.update_product_counts(self.stdout)
        self.stdout.write(self.style.SUCCESS(f'--- {self.API_SOURCE} å…¨å·¥ç¨‹å®Œäº† ---'))

    def _process_batch(self, products_data, relations_map, processed_raw_ids):
        """åå‰è§£æ±ºã‹ã‚‰UPSERTã¾ã§ã‚’ãƒãƒƒãƒå®Ÿè¡Œ"""
        self._resolve_entity_names_to_pks(products_data, relations_map)
        
        # raw_data_id ã¯ AdultProduct ã®ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã§ã¯ãªã„ãŸã‚ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹åŒ–å‰ã« pop
        for p in products_data:
            p.pop('raw_data_id', None)

        products_to_upsert = [AdultProduct(**data) for data in products_data]
        
        with transaction.atomic():
            # bulk_create ã® update_conflicts ã‚’ä½¿ç”¨ã—ã¦ä¸€æ‹¬ UPSERT
            fk_fields = [f.attname for f in AdultProduct._meta.fields if isinstance(f, models.ForeignKey)]
            update_fields = [
                'title', 'release_date', 'affiliate_url', 'price', 
                'image_url_list', 'sample_movie_url', 'updated_at', 'is_active'
            ] + fk_fields

            AdultProduct.objects.bulk_create(
                products_to_upsert,
                update_conflicts=True,
                unique_fields=['product_id_unique'],
                update_fields=update_fields
            )
            
            # M2MåŒæœŸç”¨ã®IDãƒãƒƒãƒ—å–å¾—
            unique_ids = [p.product_id_unique for p in products_to_upsert]
            product_db_id_map = {obj.product_id_unique: obj.id for obj in 
                                AdultProduct.objects.filter(product_id_unique__in=unique_ids)}
            
            self._synchronize_many_to_many(products_to_upsert, product_db_id_map, relations_map)
            
            # Rawãƒ‡ãƒ¼ã‚¿ã®å‡¦ç†å®Œäº†ãƒ•ãƒ©ã‚°æ›´æ–°
            RawApiData.objects.filter(id__in=processed_raw_ids).update(
                migrated=True, updated_at=timezone.now()
            )
        self.stdout.write(f'ãƒãƒƒãƒ {len(processed_raw_ids)} ä»¶ã‚’ä¿å­˜å®Œäº†')

    def _synchronize_many_to_many(self, products_to_upsert, product_db_id_map, relations_map):
        """ManyToManyãƒªãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆå¥³å„ªãƒ»ã‚¸ãƒ£ãƒ³ãƒ«ï¼‰ã®åŒæœŸ"""
        product_db_ids = list(product_db_id_map.values())
        if not product_db_ids: return

        for Model, key in [(Genre, 'genres_ids'), (Actress, 'actresses_ids')]:
            rel_name = ENTITY_RELATION_KEYS[Model]
            through_model = getattr(AdultProduct, rel_name).through
            through_model.objects.filter(adultproduct_id__in=product_db_ids).delete()
            
            new_rels = []
            # relations_map ã«æˆ»ã™ãŸã‚ã« products_to_upsert ã® product_id_unique ã‹ã‚‰è§£æ±º
            # (ãŸã ã— _resolve_entity_names_to_pks å†…ã§ raw_id ãƒ™ãƒ¼ã‚¹ã§ç®¡ç†ã—ã¦ã„ã‚‹ãŸã‚æ³¨æ„)
            # ã“ã“ã§ã¯ã‚·ãƒ³ãƒ—ãƒ«ã«ã™ã‚‹ãŸã‚ normalize_duga_data æ™‚ã® product_id_unique ã‚’ä½¿ã†è¨­è¨ˆã‚‚å¯
            # ã“ã“ã¯ç¾åœ¨ã® relations_map æ§‹é€ ï¼ˆraw_id ã‚­ãƒ¼ï¼‰ã‚’ç¶­æŒã—ã¾ã™
            
            # å®Ÿéš›ã«ã¯ products_to_upsert ã« raw_data_id ã¯ã‚‚ã†ãªã„ã®ã§ã€
            # raw_id ã‚’ä¸€æ™‚çš„ã«ä¿æŒã™ã‚‹ã‹ relations_map ã®ã‚­ãƒ¼æ§‹æˆã‚’åˆã‚ã›ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚
            # ä»Šå›ã¯ products_to_upsert ãƒ«ãƒ¼ãƒ—ã§ã¯ãªã products_data (dict) ã¨ã®é–¢ä¿‚æ€§ã§å¾©å…ƒã—ã¾ã™ã€‚
            pass # (ä¸‹è¨˜ _process_batch ã§ raw_id ã‚’ pop ã™ã‚‹å‰ã«å‡¦ç†ã™ã‚‹ã®ãŒå®‰å…¨)

    def _process_batch(self, products_data, relations_map, processed_raw_ids):
        """(ä¿®æ­£) raw_data_id ã‚’ä½¿ã£ã¦ M2M ã‚’è§£æ±ºã—ã¦ã‹ã‚‰ pop ã™ã‚‹"""
        self._resolve_entity_names_to_pks(products_data, relations_map)
        
        # ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹åŒ–
        products_to_upsert = []
        raw_id_to_unique = {}
        for d in products_data:
            rid = d.pop('raw_data_id', None)
            p_obj = AdultProduct(**d)
            products_to_upsert.append(p_obj)
            if rid: raw_id_to_unique[rid] = p_obj.product_id_unique

        with transaction.atomic():
            update_fields = [
                'title', 'release_date', 'affiliate_url', 'price', 
                'image_url_list', 'sample_movie_url', 'updated_at', 'is_active'
            ] + [f.attname for f in AdultProduct._meta.fields if isinstance(f, models.ForeignKey)]

            AdultProduct.objects.bulk_create(
                products_to_upsert,
                update_conflicts=True,
                unique_fields=['product_id_unique'],
                update_fields=update_fields
            )
            
            db_id_map = {obj.product_id_unique: obj.id for obj in AdultProduct.objects.filter(
                product_id_unique__in=[p.product_id_unique for p in products_to_upsert]
            )}
            
            # M2M åŒæœŸå‡¦ç†
            for Model, rel_key in [(Genre, 'genres_ids'), (Actress, 'actresses_ids')]:
                field_name = ENTITY_RELATION_KEYS[Model]
                through = getattr(AdultProduct, field_name).through
                through.objects.filter(adultproduct_id__in=db_id_map.values()).delete()
                
                rels = []
                for rid, rel_data in relations_map.items():
                    uid = raw_id_to_unique.get(rid)
                    pid = db_id_map.get(uid)
                    if pid:
                        for eid in rel_data.get(rel_key, []):
                            rels.append(through(**{'adultproduct_id': pid, f'{Model.__name__.lower()}_id': eid}))
                if rels:
                    through.objects.bulk_create(rels, ignore_conflicts=True)

            RawApiData.objects.filter(id__in=processed_raw_ids).update(migrated=True, updated_at=timezone.now())

    def update_product_counts(self, stdout):
        """å…¨ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ã®ä½œå“æ•°ã‚«ã‚¦ãƒ³ãƒˆã‚’ã‚µãƒ–ã‚¯ã‚¨ãƒªã§æ›´æ–°"""
        stdout.write("\n--- ä½œå“æ•°é›†è¨ˆæ›´æ–° ---")
        with transaction.atomic():
            MAPPING = [
                (Actress, 'actresses'), (Genre, 'genres'),
                (Maker, 'maker_id'), (Label, 'label_id'),
                (Director, 'director_id'), (Series, 'series_id'),
            ]
            for Model, field in MAPPING:
                if field.endswith('_id'):
                    subq = AdultProduct.objects.filter(**{field: OuterRef('pk')}).values(field).annotate(c=Count('id')).values('c')[:1]
                else:
                    through = getattr(AdultProduct, field).through
                    fk = f"{Model.__name__.lower()}_id"
                    subq = through.objects.filter(**{fk: OuterRef('pk')}).values(fk).annotate(c=Count('adultproduct_id')).values('c')[:1]
                
                Model.objects.filter(api_source=self.API_SOURCE).update(
                    product_count=Coalesce(Subquery(subq, output_field=models.IntegerField()), 0)
                )
                stdout.write(f'âœ… {Model.__name__} ã‚«ã‚¦ãƒ³ãƒˆå®Œäº†')