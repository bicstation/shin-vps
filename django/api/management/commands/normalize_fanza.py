# -*- coding: utf-8 -*-
import logging
import re
from django.core.management.base import BaseCommand
from django.db import transaction, models
from django.db.models import Count, OuterRef, Subquery
from django.db.models.functions import Coalesce
from django.utils import timezone 

# é–¢é€£ãƒ¢ãƒ‡ãƒ«ï¼šAuthorï¼ˆè‘—è€…ï¼‰ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆã«è¿½åŠ 
from api.models import (
    RawApiData, AdultProduct, Genre, Actress, 
    Director, Maker, Label, Series, Author
)

# ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ï¼šé€²åŒ–ã—ãŸParserã¨EntityManager
from api.utils.adult.fanza_normalizer import normalize_fanza_data 
from api.utils.adult.entity_manager import get_or_create_entity 

logger = logging.getLogger('normalize_adult')

# ğŸš€ ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ç®¡ç†ãƒªã‚¹ãƒˆï¼šAuthorã‚’çµ±åˆ
ENTITY_MODELS = [Maker, Label, Director, Series, Genre, Actress, Author]
ENTITY_RELATION_KEYS = {
    Maker: 'maker', 
    Label: 'label', 
    Director: 'director', 
    Series: 'series',
    Genre: 'genres', 
    Actress: 'actresses',
    Author: 'authors' # ğŸ†• é›»å­æ›¸ç±ãƒ»ã‚³ãƒŸãƒƒã‚¯ç”¨
}

class Command(BaseCommand):
    help = 'RawApiData(API/ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°)ã‚’AdultProductã¸çµ±åˆæ­£è¦åŒ–ã—ã€æœ€é«˜ç”»è³ªã§UPSERTã—ã¾ã™ã€‚'

    def add_arguments(self, parser):
        parser.add_argument('--limit', type=int, help='å‡¦ç†ä»¶æ•°åˆ¶é™')
        parser.add_argument('--source', type=str, default=None, help='FANZA or DMM')
        parser.add_argument('--re-run', action='store_true', help='migrated=Trueã®ãƒ‡ãƒ¼ã‚¿ã‚‚å†å‡¦ç†ã™ã‚‹')

    def _optimize_url(self, url):
        """DMM/FANZAã®ç”»åƒURLã‚’æœ€é«˜ç”»è³ª(Large)ã¸å¤‰æ›ã€‚é›»å­æ›¸ç±ç³»ãƒ‰ãƒ¡ã‚¤ãƒ³ã‚‚ã‚«ãƒãƒ¼"""
        if not url: return ""
        if url.startswith('//'): url = 'https:' + url
        # å‹•ç”»(pics.dmm.com)ãŠã‚ˆã³é›»å­æ›¸ç±(ebook-assets)ã®ç”»åƒç½®æ›ã«å¯¾å¿œ
        if any(domain in url for domain in ['pics.dmm', 'ebook-assets']):
            url = re.sub(r'p[s|t]\.jpg', 'pl.jpg', url, flags=re.IGNORECASE)
            url = re.sub(r'_[ms]\.jpg', '_l.jpg', url, flags=re.IGNORECASE)
        return url

    def handle(self, *args, **options):
        sources = [options['source'].upper()] if options['source'] else ['FANZA', 'DMM']
        re_run = options.get('re_run', False)
        
        for source in sources:
            self.stdout.write(self.style.NOTICE(f'\n--- {source} çµ±åˆæ­£è¦åŒ–ãƒ»é«˜ç”»è³ªåŒ–é–‹å§‹ ---'))
            
            filters = {'api_source': source}
            if not re_run:
                filters['migrated'] = False
                
            raw_qs = RawApiData.objects.filter(**filters).order_by('id')
            if options['limit']:
                raw_qs = raw_qs[:options['limit']]

            total = raw_qs.count()
            if total == 0:
                self.stdout.write(self.style.WARNING(f"{source} ã®æœªå‡¦ç†ãƒ‡ãƒ¼ã‚¿ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚"))
                continue

            batch_size = 500
            # ğŸš€ ãƒãƒƒãƒå†…é‡è¤‡æ’é™¤ï¼šproduct_id_uniqueã‚’ã‚­ãƒ¼ã«æœ€æ–°ãƒ‡ãƒ¼ã‚¿ã‚’ä¿æŒ
            batch_dict = {} 
            batch_relations = {}
            processed_raw_ids = []

            for raw_instance in raw_qs:
                try:
                    # ğŸ”¥ å¿ƒè‡“éƒ¨ï¼šAPI/ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°/èª­ã¿æ”¾é¡Œã‚’è‡ªå‹•åˆ¤åˆ¥ã—ã¦ãƒ‘ãƒ¼ã‚¹
                    p_list, r_list = normalize_fanza_data(raw_instance)
                    if not p_list:
                        raw_instance.migrated = True
                        raw_instance.save(update_fields=['migrated'])
                        continue

                    # 1ã¤ã®RawDataã«å¯¾ã—1å•†å“ã‚’åŸå‰‡ã¨ã—ã¦å‡¦ç†
                    p_data = p_list[0]
                    r_data = r_list[0]
                    unique_id = p_data['product_id_unique']

                    # ğŸ–¼ï¸ ç”»åƒãƒªã‚¹ãƒˆã®é«˜ç”»è³ªåŒ–
                    if 'image_url_list' in p_data and p_data['image_url_list']:
                        p_data['image_url_list'] = list(dict.fromkeys(
                            filter(None, [self._optimize_url(u) for u in p_data['image_url_list']])
                        ))

                    # ğŸ¥ å‹•ç”»ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ç”»åƒã‚‚é«˜ç”»è³ªåŒ–
                    if isinstance(p_data.get('sample_movie_url'), dict):
                        preview = p_data['sample_movie_url'].get('preview_image')
                        if preview:
                            p_data['sample_movie_url']['preview_image'] = self._optimize_url(preview)

                    p_data['api_source'] = source.lower()
                    p_data['updated_at'] = timezone.now()

                    # åŒä¸€ãƒãƒƒãƒå†…ã«åŒã˜IDãŒã‚ã‚Œã°ã€å¾Œã‹ã‚‰æ¥ãŸãƒ‡ãƒ¼ã‚¿ï¼ˆæœ€æ–°ï¼‰ã§è¾æ›¸ã‚’æ›´æ–°
                    batch_dict[unique_id] = p_data
                    batch_relations[unique_id] = r_data
                    processed_raw_ids.append(raw_instance.id)

                    if len(batch_dict) >= batch_size:
                        self._process_batch(list(batch_dict.values()), batch_relations, processed_raw_ids, source)
                        batch_dict, batch_relations, processed_raw_ids = {}, {}, []

                except Exception as e:
                    self.stdout.write(self.style.ERROR(f"Raw ID {raw_instance.id} è§£æä¸èƒ½: {e}"))
                    logger.exception(f"Error processing RawApiData {raw_instance.id}")

            if batch_dict:
                self._process_batch(list(batch_dict.values()), batch_relations, processed_raw_ids, source)

        self._update_all_product_counts()
        self.stdout.write(self.style.SUCCESS('\nâœ… å…¨ã¦ã®æ­£è¦åŒ–ãƒ»UPSERTå·¥ç¨‹ãŒå®Œäº†ã—ã¾ã—ãŸ'))

    def _process_batch(self, products_data, relations_map, raw_ids, source):
        """ãƒã‚¹ã‚¿ãƒ¼è§£æ±ºã€çµ±åˆUPSERTã€M2MåŒæœŸã‚’ä¸€æŒ™ã«å®Ÿè¡Œ"""
        
        # 1. ãƒã‚¹ã‚¿ãƒ¼ãƒ‡ãƒ¼ã‚¿ã®åå‰è§£æ±ºï¼ˆAuthorã‚’å«ã‚€å…¨æ–¹ä½ï¼‰
        all_names = {M: set() for M in ENTITY_MODELS}
        for p in products_data:
            for M in [Maker, Label, Director, Series]:
                key = ENTITY_RELATION_KEYS[M]
                if val := p.get(key): all_names[M].add(val)
        
        for r in relations_map.values():
            for M in [Genre, Actress, Author]: # ğŸ†• Authorã‚’è¿½åŠ 
                key = ENTITY_RELATION_KEYS[M]
                for name in r.get(key, []): 
                    if name: all_names[M].add(name)

        # Entityã‚’ä¸€æ‹¬ç”Ÿæˆãƒ»å–å¾—
        pk_maps = {M: get_or_create_entity(M, list(names), source) for M, names in all_names.items() if names}

        # 2. å¤–éƒ¨ã‚­ãƒ¼(FK)ã®IDç½®æ›ã¨ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹åŒ–
        upsert_list = []
        for p in products_data:
            # ãƒ¢ãƒ‡ãƒ«ã«å­˜åœ¨ã—ãªã„ä¸€æ™‚çš„ãªä½œæ¥­ã‚­ãƒ¼ã‚’å‰Šé™¤
            p.pop('image_url', None) 
            p.pop('raw_data_id', None)
            
            for M in [Maker, Label, Director, Series]:
                key = ENTITY_RELATION_KEYS[M]
                name = p.pop(key, None)
                p[f'{key}_id'] = pk_maps.get(M, {}).get(name) if name else None
            
            upsert_list.append(AdultProduct(**p))

        if not upsert_list: return

        # 3. ğŸ›¡ï¸ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã¸ã® çµ±åˆUPSERT å®Ÿè¡Œ
        # ã“ã“ã§APIãƒ‡ãƒ¼ã‚¿ã¨ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã®ã€Œèåˆã€ãŒèµ·ã“ã‚Šã¾ã™
        with transaction.atomic():
            AdultProduct.objects.bulk_create(
                upsert_list,
                update_conflicts=True,
                unique_fields=['product_id_unique'],
                update_fields=[
                    'title', 'affiliate_url', 'image_url_list', 'sample_movie_url', 
                    'price', 'release_date', 'maker_id', 'label_id', 'director_id', 
                    'series_id', 'updated_at',
                    # ğŸ†• å¼·åŒ–ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ï¼šã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã‚„èª­ã¿æ”¾é¡Œå›ºæœ‰ã®ãƒ‡ãƒ¼ã‚¿ã‚‚ç¢ºå®Ÿã«æ›´æ–°
                    'rich_description', 'product_description', 'is_unlimited',
                    'unlimited_channels', 'volume', 'maker_product_id', 'tachiyomi_url'
                ]
            )

            # 4. M2Mé–¢ä¿‚ã®åŒæœŸï¼ˆGenre, Actress, Authorï¼‰
            # UPSERTå¾Œã®æœ€æ–°IDã‚’å–å¾—
            db_map = {obj.product_id_unique: obj.id for obj in AdultProduct.objects.filter(
                product_id_unique__in=[p.product_id_unique for p in upsert_list]
            )}

            for M in [Genre, Actress, Author]: # ğŸ†• Authorã‚’åŒæœŸãƒ«ãƒ¼ãƒ—ã«è¿½åŠ 
                key = ENTITY_RELATION_KEYS[M]
                through_model = getattr(AdultProduct, key).through
                
                # æ—¢å­˜ã®ç´ä»˜ã‘ã‚’ä¸€æ—¦ãƒªã‚»ãƒƒãƒˆï¼ˆæœ€æ–°ã®API/ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°æƒ…å ±ã‚’æ­£ã¨ã™ã‚‹ãŸã‚ï¼‰
                through_model.objects.filter(adultproduct_id__in=db_map.values()).delete()
                
                rels = []
                for unique_id, r in relations_map.items():
                    pid = db_map.get(unique_id)
                    m_map = pk_maps.get(M, {})
                    for name in r.get(key, []):
                        if eid := m_map.get(name):
                            rels.append(through_model(**{'adultproduct_id': pid, f'{M.__name__.lower()}_id': eid}))
                
                if rels:
                    through_model.objects.bulk_create(rels, ignore_conflicts=True)

            # å…ƒãƒ‡ãƒ¼ã‚¿ã®å‡¦ç†æ¸ˆã¿ãƒ•ãƒ©ã‚°ã‚’ç«‹ã¦ã‚‹
            RawApiData.objects.filter(id__in=raw_ids).update(migrated=True, updated_at=timezone.now())

    def _update_all_product_counts(self):
        """Authorã‚’å«ã‚€å…¨ãƒã‚¹ã‚¿ãƒ¼ã®ä½œå“æ•°ã‚«ã‚¦ãƒ³ãƒˆã‚’é«˜é€Ÿä¸€æ‹¬æ›´æ–°"""
        self.stdout.write("å„ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ã®ä½œå“æ•°ã‚«ã‚¦ãƒ³ãƒˆã‚’æ›´æ–°ä¸­...")
        with transaction.atomic():
            MAPPING = [
                (Actress, 'actresses'), (Genre, 'genres'), (Author, 'authors'), # ğŸ†• Author
                (Maker, 'maker_id'), (Label, 'label_id'),
                (Director, 'director_id'), (Series, 'series_id'),
            ]
            for Model, field in MAPPING:
                if field.endswith('_id'):
                    # FKãƒ‘ã‚¿ãƒ¼ãƒ³ã®é›†è¨ˆ
                    subq = AdultProduct.objects.filter(**{field: OuterRef('pk')}).values(field).annotate(c=Count('id')).values('c')[:1]
                else:
                    # M2Mãƒ‘ã‚¿ãƒ¼ãƒ³ã®é›†è¨ˆ
                    through = getattr(AdultProduct, field).through
                    fk = f"{Model.__name__.lower()}_id"
                    subq = through.objects.filter(**{fk: OuterRef('pk')}).values(fk).annotate(c=Count('adultproduct_id')).values('c')[:1]
                
                Model.objects.update(product_count=Coalesce(Subquery(subq, output_field=models.IntegerField()), 0))