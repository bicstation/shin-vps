# /mnt/c/dev/SHIN-VPS/django/api/management/commands/test_link_locator.py

import requests
import xml.etree.ElementTree as ET
from datetime import datetime
from django.core.management.base import BaseCommand
from .linkshare_bc_client import LinkShareAPIClient

class Command(BaseCommand):
    help = 'APIãƒªãƒ³ã‚¯ã¨ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°è£½å“ã®ãƒãƒƒãƒãƒ³ã‚°ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³'

    def handle(self, *args, **options):
        client = LinkShareAPIClient()
        client.refresh_token_if_expired()
        
        token = client.access_token
        mid = "2557"
        
        # 1. APIã‹ã‚‰ãƒªãƒ³ã‚¯ã‚’ãƒ­ãƒ¼ãƒ‰ï¼ˆ1ãƒšãƒ¼ã‚¸ç›®ã ã‘ã§ãƒ†ã‚¹ãƒˆï¼‰
        self.stdout.write(self.style.NOTICE("ğŸ“¡ APIã‹ã‚‰ãƒªãƒ³ã‚¯ã‚’ãƒ­ãƒ¼ãƒ‰ä¸­..."))
        start_date = "01012024"
        end_date = datetime.now().strftime("%m%d%Y")
        url = f"https://api.linksynergy.com/linklocator/1.0/getTextLinks/{mid}/-1/{start_date}/{end_date}/-1/1"
        
        res = requests.get(url, headers={'Authorization': f'Bearer {token}', 'Accept': 'application/xml'})
        
        all_api_links = []
        if res.status_code == 200:
            root = ET.fromstring(res.text)
            ns = {'ns1': 'http://endpoint.linkservice.linkshare.com/'}
            for item in root.findall('.//ns1:return', ns):
                all_api_links.append({
                    'name': item.findtext('ns1:linkName', namespaces=ns),
                    'click_url': item.findtext('ns1:clickURL', namespaces=ns)
                })
        
        self.stdout.write(self.style.SUCCESS(f"âœ… {len(all_api_links)}ä»¶ã®ãƒªãƒ³ã‚¯ã‚’ãƒ¡ãƒ¢ãƒªã«å±•é–‹ã—ã¾ã—ãŸã€‚"))

        # 2. ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã§è¦‹ã¤ã‘ãŸã¨ä»®å®šã™ã‚‹è£½å“ãƒªã‚¹ãƒˆ
        # å®Ÿéš›ã®é‹ç”¨ã§ã¯DBã‹ã‚‰å¼•ã£å¼µã£ã¦ãã‚‹ãƒªã‚¹ãƒˆã«ãªã‚Šã¾ã™
        scraped_products = [
            "Alienware m18", 
            "Inspiron 3030",
            "XPS 13",
            "éå®Ÿåœ¨ãƒ‘ã‚½ã‚³ãƒ³123" 
        ]

        # æ±ç”¨ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”¨ãƒªãƒ³ã‚¯ï¼ˆãƒªã‚¹ãƒˆã®æœ€åˆã®æ–¹ã«ã‚ã‚‹æ±ç”¨çš„ãªã‚‚ã®ï¼‰
        fallback_link = all_api_links[0] if all_api_links else None

        self.stdout.write(self.style.NOTICE("\n--- è‡ªå‹•ç´ä»˜ã‘ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ ---"))

        for product_name in scraped_products:
            self.stdout.write(f"\nğŸ” ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°è£½å“: {product_name}")
            
            # éƒ¨åˆ†ä¸€è‡´ã§æ¤œç´¢
            match = next((l for l in all_api_links if product_name.lower() in l['name'].lower()), None)
            
            if match:
                self.stdout.write(self.style.SUCCESS(f"  ğŸ¯ ç´ä»˜ã‘æˆåŠŸ: {match['name']}"))
                self.stdout.write(f"  ğŸ”— æœ€çµ‚URL: {match['click_url']}")
            else:
                self.stdout.write(self.style.WARNING(f"  âš ï¸ è©²å½“ãªã—ã€‚æ±ç”¨ãƒªãƒ³ã‚¯ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚"))
                self.stdout.write(f"  ğŸ”— æœ€çµ‚URL: {fallback_link['click_url'] if fallback_link else 'N/A'}")