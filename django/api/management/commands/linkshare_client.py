import os
import base64
import requests
from xml.etree import ElementTree as ET
from urllib.parse import urljoin, urlencode
# ğŸ’¡ tqdm ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from tqdm import tqdm 
import time

class LinkShareAPIClient:
    """
    LinkShare APIã¨ã®é€šä¿¡ã‚’ç®¡ç†ã™ã‚‹ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚¯ãƒ©ã‚¹ã€‚
    ãƒˆãƒ¼ã‚¯ãƒ³å–å¾—ã€åºƒå‘Šä¸»ä¸€è¦§å–å¾—ã€å•†å“æ¤œç´¢ã®ãƒ­ã‚¸ãƒƒã‚¯ã‚’å®Ÿè£…ã€‚
    """
    BASE_URL = "https://api.linksynergy.com/"
    
    # --- __init__ ã¨ã‚¢ã‚¯ã‚»ã‚¹ãƒˆãƒ¼ã‚¯ãƒ³å–å¾—ãƒ¡ã‚½ãƒƒãƒ‰ (get_access_token) ---
    def __init__(self):
        # ç’°å¢ƒå¤‰æ•°ã‹ã‚‰èªè¨¼æƒ…å ±ã‚’å–å¾—
        self.client_id = os.environ.get('LS_CLIENT_ID')
        self.client_secret = os.environ.get('LS_CLIENT_SECRET')
        self.account_id = os.environ.get('LS_ACCOUNT_ID')
        self.token_url = os.environ.get('LS_TOKEN_URL', urljoin(self.BASE_URL, 'token'))
        self.access_token = None
        
        if not all([self.client_id, self.client_secret, self.account_id]):
            raise ValueError("LinkShare APIã®èªè¨¼æƒ…å ± (LS_CLIENT_ID, LS_CLIENT_SECRET, LS_ACCOUNT_ID) ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")

    def _generate_token_key(self):
        auth_string = f"{self.client_id}:{self.client_secret}"
        return base64.b64encode(auth_string.encode('utf-8')).decode('utf-8')

    def get_access_token(self):
        if self.access_token:
            return 
            
        token_key = self._generate_token_key()
        
        headers = {
            'Authorization': f'Bearer {token_key}',
            'Content-Type': 'application/x-www-form-urlencoded',
        }
        data = {
            'grant_type': 'password',
            'scope': self.account_id
        }
        
        print(f"ğŸ“¡ ã‚¢ã‚¯ã‚»ã‚¹ãƒˆãƒ¼ã‚¯ãƒ³ã‚’ {self.token_url} ã«ãƒªã‚¯ã‚¨ã‚¹ãƒˆä¸­...")

        try:
            response = requests.post(self.token_url, headers=headers, data=data)
            response.raise_for_status()
            
            token_data = response.json()
            self.access_token = token_data.get('access_token')
            
            if self.access_token:
                print(f"âœ… ã‚¢ã‚¯ã‚»ã‚¹ãƒˆãƒ¼ã‚¯ãƒ³å–å¾—æˆåŠŸã€‚æœ‰åŠ¹æœŸé™: {token_data.get('expires_in')} ç§’")
            else:
                print(f"âŒ ã‚¢ã‚¯ã‚»ã‚¹ãƒˆãƒ¼ã‚¯ãƒ³å–å¾—å¤±æ•—ã€‚ãƒ¬ã‚¹ãƒãƒ³ã‚¹: {token_data}")
                raise Exception("ã‚¢ã‚¯ã‚»ã‚¹ãƒˆãƒ¼ã‚¯ãƒ³ãŒãƒ¬ã‚¹ãƒãƒ³ã‚¹ã«å«ã¾ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
                
        except requests.exceptions.RequestException as e:
            print(f"âŒ ã‚¢ã‚¯ã‚»ã‚¹ãƒˆãƒ¼ã‚¯ãƒ³ãƒªã‚¯ã‚¨ã‚¹ãƒˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
            raise
            
    # --- åºƒå‘Šä¸»ä¸€è¦§å–å¾—ãƒ¡ã‚½ãƒƒãƒ‰ (get_advertiser_list / _parse_advertiser_xml) ---
    def get_advertiser_list(self):
        if not self.access_token:
            self.get_access_token()

        endpoint = urljoin(self.BASE_URL, 'advertisersearch/1.0')
        headers = {
            'Authorization': f'Bearer {self.access_token}',
        }
        
        print(f"ğŸ“¡ åºƒå‘Šä¸»ä¸€è¦§ã‚’ {endpoint} ã«ãƒªã‚¯ã‚¨ã‚¹ãƒˆä¸­...")

        try:
            response = requests.get(endpoint, headers=headers)
            response.raise_for_status()
            return self._parse_advertiser_xml(response.text)

        except requests.exceptions.RequestException as e:
            print(f"âŒ åºƒå‘Šä¸»ä¸€è¦§ãƒªã‚¯ã‚¨ã‚¹ãƒˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
            return []
            
    def _parse_advertiser_xml(self, xml_string):
        advertisers = []
        try:
            root = ET.fromstring(xml_string)
            for merchant_elem in root.findall('.//merchant'):
                mid = merchant_elem.find('mid').text if merchant_elem.find('mid') is not None else 'N/A'
                name = merchant_elem.find('merchantname').text if merchant_elem.find('merchantname') is not None else 'N/A'
                advertisers.append({'mid': mid, 'merchantname': name})
            return advertisers
        except ET.ParseError as e:
            print(f"âŒ XMLãƒ‘ãƒ¼ã‚¹ã‚¨ãƒ©ãƒ¼: {e}")
            return []
    
    # ----------------------------------------------------------------------------------
    # ãƒšãƒ¼ã‚¸ãƒãƒ¼ã‚·ãƒ§ãƒ³ã¨XMLãƒ‘ãƒ¼ã‚¹ã®ä¿®æ­£
    # ----------------------------------------------------------------------------------
            
    def _extract_item_data(self, item_elem: ET.Element) -> dict:
        """å˜ä¸€ã® <item> è¦ç´ ã‹ã‚‰å¿…è¦ãªãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’æŠ½å‡ºã—ã¦è¾æ›¸å½¢å¼ã§è¿”ã™"""
        
        # ã‚«ãƒ†ã‚´ãƒªã®å‡¦ç†: <category><primary>ã¨<secondary>ã‚’çµåˆ
        category_elem = item_elem.find('category')
        primary_cat = category_elem.findtext('primary') if category_elem is not None else ''
        secondary_cat = category_elem.findtext('secondary') if category_elem is not None else ''
        full_category = f"{primary_cat}~~{secondary_cat}".strip("~~")

        # ä¾¡æ ¼ã®å‡¦ç†: é€šè²¨å±æ€§ã‚‚æŠ½å‡º
        price_elem = item_elem.find('price')
        sale_price_elem = item_elem.find('saleprice')

        # å•†å“æƒ…å ±è¾æ›¸ã‚’æ§‹ç¯‰ï¼ˆFTPå½¢å¼ã«è¿‘ã¥ã‘ã‚‹ï¼‰
        product_data = {
            'mid': item_elem.findtext('mid'),
            'merchantname': item_elem.findtext('merchantname'),
            'linkid': item_elem.findtext('linkid'),
            'createdon': item_elem.findtext('createdon'),
            'sku': item_elem.findtext('sku'),
            'productname': item_elem.findtext('productname').strip() if item_elem.findtext('productname') else 'N/A',
            'category': full_category,
            'price': {
                'value': price_elem.text,
                'currency': price_elem.get('currency')
            } if price_elem is not None else None,
            'saleprice': {
                'value': sale_price_elem.text,
                'currency': sale_price_elem.get('currency')
            } if sale_price_elem is not None else None,
            'upccode': item_elem.findtext('upccode'),
            'description_short': item_elem.findtext('description/short'),
            'description_long': item_elem.findtext('description/long'),
            'keywords': item_elem.findtext('keywords'),
            'linkurl': item_elem.findtext('linkurl'),
            'imageurl': item_elem.findtext('imageurl'),
        }
        return product_data

    def _fetch_product_page(self, params: dict) -> tuple[dict, int, int]:
        """
        å•†å“æ¤œç´¢APIã®å˜ä¸€ãƒšãƒ¼ã‚¸ã‚’ãƒ•ã‚§ãƒƒãƒã—ã€ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã¨å•†å“ãƒªã‚¹ãƒˆã‚’å«ã‚€è¾æ›¸ã‚’è¿”ã™
        """
        if not self.access_token:
            self.get_access_token() 

        endpoint = urljoin(self.BASE_URL, 'productsearch/1.0')
        headers = {'Authorization': f'Bearer {self.access_token}'}
        url_with_params = f"{endpoint}?{urlencode(params)}"
        
        # ğŸ’¡ tqdmè¡¨ç¤ºä¸­ã¯ã€å†—é•·ãªãƒ­ã‚°ã¯æŠ‘åˆ¶ã™ã‚‹
        # print(f"ğŸ“¡ ãƒšãƒ¼ã‚¸ {params.get('pagenumber', 1)} ã®å•†å“ã‚’ {url_with_params} ã«ãƒªã‚¯ã‚¨ã‚¹ãƒˆä¸­...")

        response = None
        try:
            response = requests.get(url_with_params, headers=headers)
            response.raise_for_status()
            
            root = ET.fromstring(response.text)
            
            # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º
            total_matches = int(root.findtext('TotalMatches') or 0)
            total_pages = int(root.findtext('TotalPages') or 0)
            
            # ã‚¢ã‚¤ãƒ†ãƒ ãƒªã‚¹ãƒˆã‚’æ§‹ç¯‰
            product_items = [
                self._extract_item_data(item_elem)
                for item_elem in root.findall('.//item')
            ]
            
            # ãƒšãƒ¼ã‚¸ã®çµæœè¾æ›¸ã‚’æ§‹ç¯‰
            page_result = {
                'TotalMatches': total_matches,
                'TotalPages': total_pages,
                'PageNumber': int(root.findtext('PageNumber') or 1),
                'items': product_items
            }
            
            return page_result, total_matches, total_pages

        except requests.exceptions.RequestException as e:
            # è‡´å‘½çš„ãªã‚¨ãƒ©ãƒ¼ã®å ´åˆã®ã¿ãƒ­ã‚°å‡ºåŠ›
            tqdm.write(f"âŒ å•†å“æ¤œç´¢ãƒªã‚¯ã‚¨ã‚¹ãƒˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
            if response is not None and response.text:
                 tqdm.write(f"APIãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚¨ãƒ©ãƒ¼è©³ç´°:\n{response.text}")
            return {}, 0, 0
        except ET.ParseError as e:
            tqdm.write(f"âŒ XMLãƒ‘ãƒ¼ã‚¹ã‚¨ãƒ©ãƒ¼: {e}")
            return {}, 0, 0
            
    def search_products(self, keyword: str = None, mid: str = None, cat: str = None, page_size: int = 100, max_pages: int = 0) -> list[dict]:
        """
        å•†å“æ¤œç´¢APIã‚’åˆ©ç”¨ã—ã¦ã€å…¨ãƒšãƒ¼ã‚¸ã®å•†å“æƒ…å ±ã‚’å–å¾—ã—ã€JSONå½¢å¼ã®ç”Ÿãƒ‡ãƒ¼ã‚¿ãƒªã‚¹ãƒˆã‚’è¿”ã™
        ãƒšãƒ¼ã‚¸å–å¾—ãƒ«ãƒ¼ãƒ—ã«ã¯ tqdm ã‚’é©ç”¨ã™ã‚‹ã€‚
        """
        all_page_results = []
        page_size = min(page_size, 100)
        
        # æœ€åˆã®ãƒšãƒ¼ã‚¸ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        initial_params = {
            'max': page_size,
            'pagenumber': 1
        }
        # æ¤œç´¢æ¡ä»¶ã®è¿½åŠ 
        if keyword: initial_params['keyword'] = keyword
        if mid: initial_params['mid'] = mid
        if cat: initial_params['cat'] = cat
        
        # æ¤œç´¢æ¡ä»¶ãŒãªã„å ´åˆã¯ã‚¨ãƒ©ãƒ¼
        if not (keyword or mid or cat):
            raise ValueError("æ¤œç´¢ã«ã¯ã€keyword, mid, cat ã®ã†ã¡å°‘ãªãã¨ã‚‚1ã¤ã‚’æŒ‡å®šã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚")

        # 1ãƒšãƒ¼ã‚¸ç›®ã‚’ãƒ•ã‚§ãƒƒãƒ
        page_result_1, total_matches, total_pages = self._fetch_product_page(initial_params)
        
        if total_matches == 0:
            return []

        # ãƒšãƒ¼ã‚¸çµæœã«MIDæƒ…å ±ã‚’ä»˜ä¸ (DBä¿å­˜ãƒ­ã‚¸ãƒƒã‚¯å¯¾å¿œã®ãŸã‚)
        mid_for_log = mid or "ALL"
        
        # 1ãƒšãƒ¼ã‚¸ç›®ã®çµæœã‚’æ ¼ç´
        all_page_results.append(page_result_1)
        
        # å–å¾—ã™ã‚‹æœ€å¤§ãƒšãƒ¼ã‚¸æ•°ã‚’æ±ºå®š
        pages_to_fetch = min(total_pages, max_pages) if max_pages > 0 else total_pages
        
        tqdm.write(f"âœ… MID {mid_for_log} åˆè¨ˆ {total_matches} ä»¶ã€å…¨ {total_pages} ãƒšãƒ¼ã‚¸ã®å•†å“ãŒãƒ’ãƒƒãƒˆã—ã¾ã—ãŸã€‚")
        
        # 2ãƒšãƒ¼ã‚¸ç›®ä»¥é™ã‚’ãƒ«ãƒ¼ãƒ—ã§ãƒ•ã‚§ãƒƒãƒ
        if pages_to_fetch > 1:
            
            # ğŸ’¡ ä¿®æ­£ç‚¹: 2ãƒšãƒ¼ã‚¸ç›®ä»¥é™ã®ãƒ«ãƒ¼ãƒ—ã« tqdm ã‚’é©ç”¨
            # æœ€åˆã®1ãƒšãƒ¼ã‚¸ã¯æ—¢ã«å–å¾—æ¸ˆã¿ãªã®ã§ã€ãƒ«ãƒ¼ãƒ—ã¯ page=2 ã‹ã‚‰ pages_to_fetch ã¾ã§
            page_range = range(2, pages_to_fetch + 1)
            
            # ãƒšãƒ¼ã‚¸å–å¾—ãƒ«ãƒ¼ãƒ—ã‚’ tqdm ã§ãƒ©ãƒƒãƒ—
            for page in tqdm(page_range, desc=f"ğŸ“š MID {mid_for_log} ãƒšãƒ¼ã‚¸å–å¾—", unit="ãƒšãƒ¼ã‚¸"):
                # APIã®1åˆ†é–“ã«100ãƒªã‚¯ã‚¨ã‚¹ãƒˆã®åˆ¶é™ã«æ³¨æ„ãŒå¿…è¦
                
                loop_params = initial_params.copy()
                loop_params['pagenumber'] = page
                
                # APIãƒªã‚¯ã‚¨ã‚¹ãƒˆã®å®Ÿè¡Œ
                page_result_n, _, _ = self._fetch_product_page(loop_params)
                
                # ãƒšãƒ¼ã‚¸çµæœãŒç©ºã§ãªãã€ã‚¨ãƒ©ãƒ¼ã‚‚ãªã„ã“ã¨ã‚’ç¢ºèªã—ã¦æ ¼ç´
                if page_result_n.get('items'):
                    all_page_results.append(page_result_n)
                else:
                    # ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°ã¯ _fetch_product_page å†…ã§æ—¢ã«å‡ºã¦ã„ã‚‹ã¯ãš
                    # é€£ç¶šã§ã‚¨ãƒ©ãƒ¼ã«ãªã£ãŸå ´åˆã€APIã®ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã«å¼•ã£ã‹ã‹ã£ã¦ã„ã‚‹å¯èƒ½æ€§
                    pass
                
                # ãƒšãƒ¼ã‚¸ã®é€”ä¸­ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãŸå ´åˆã€ç„¡é™ãƒ«ãƒ¼ãƒ—ã‚’é˜²ããŸã‚break (ã‚ªãƒ—ã‚·ãƒ§ãƒ³)
                if not page_result_n:
                    tqdm.write(f"âš ï¸ ãƒšãƒ¼ã‚¸ {page} ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸã€‚ã“ã®MIDã®ãƒšãƒ¼ã‚¸ãƒ³ã‚°ã‚’ä¸­æ–­ã—ã¾ã™ã€‚")
                    break

        # å–å¾—ã—ãŸå…¨ãƒšãƒ¼ã‚¸ã®çµæœãƒªã‚¹ãƒˆã‚’è¿”ã™
        tqdm.write(f"âœ… MID {mid_for_log} ã®å…¨ {len(all_page_results)} ãƒšãƒ¼ã‚¸ã®çµæœã‚’åé›†å®Œäº†ã—ã¾ã—ãŸã€‚")
        return all_page_results