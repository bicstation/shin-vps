import os
import base64
import requests
from xml.etree import ElementTree as ET
from urllib.parse import urljoin, urlencode
from tqdm import tqdm 
import time
from datetime import datetime, timedelta, timezone

class LinkShareAPIClient:
    """
    LinkShare APIã¨ã®é€šä¿¡ã‚’ç®¡ç†ã™ã‚‹ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚¯ãƒ©ã‚¹ã€‚
    ãƒˆãƒ¼ã‚¯ãƒ³å–å¾—ã€åºƒå‘Šä¸»ä¸€è¦§å–å¾—ã€å•†å“æ¤œç´¢ã®ãƒ­ã‚¸ãƒƒã‚¯ã‚’å®Ÿè£…ã€‚
    """
    BASE_URL = "https://api.linksynergy.com/"
    
    def __init__(self):
        # ç’°å¢ƒå¤‰æ•°ã‹ã‚‰èªè¨¼æƒ…å ±ã‚’å–å¾—
        self.client_id = os.environ.get('LS_CLIENT_ID')
        self.client_secret = os.environ.get('LS_CLIENT_SECRET')
        self.account_id = os.environ.get('LS_ACCOUNT_ID')
        self.token_url = os.environ.get('LS_TOKEN_URL', urljoin(self.BASE_URL, 'token'))
        
        # ğŸ’¡ ãƒˆãƒ¼ã‚¯ãƒ³ã¨æœ‰åŠ¹æœŸé™æƒ…å ±ã‚’ä¿æŒ
        self.access_token = None
        self.token_expiry_time = None # datetimeã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã§æœ‰åŠ¹æœŸé™ã‚’ä¿æŒ

        if not all([self.client_id, self.client_secret, self.account_id]):
            raise ValueError("LinkShare APIã®èªè¨¼æƒ…å ± (LS_CLIENT_ID, LS_CLIENT_SECRET, LS_ACCOUNT_ID) ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")

    def _generate_token_key(self):
        auth_string = f"{self.client_id}:{self.client_secret}"
        return base64.b64encode(auth_string.encode('utf-8')).decode('utf-8')

    def _is_token_expired(self, buffer_seconds=60):
        """
        ãƒˆãƒ¼ã‚¯ãƒ³ãŒæœŸé™åˆ‡ã‚Œã‹ã©ã†ã‹ã€ã¾ãŸã¯æœŸé™åˆ‡ã‚ŒãŒè¿‘ã„ã‹ (ãƒãƒƒãƒ•ã‚¡æ™‚é–“å†…) ã‚’ãƒã‚§ãƒƒã‚¯ã™ã‚‹ã€‚
        """
        if not self.access_token or not self.token_expiry_time:
            return True
            
        # æœŸé™åˆ‡ã‚Œæ™‚åˆ»ã‹ã‚‰ãƒãƒƒãƒ•ã‚¡ç§’ã‚’å¼•ã„ãŸæ™‚åˆ»ã¨æ¯”è¼ƒ
        return datetime.now(timezone.utc) >= (self.token_expiry_time - timedelta(seconds=buffer_seconds))

    def refresh_token_if_expired(self):
        if self._is_token_expired():
            tqdm.write("âš ï¸ ã‚¢ã‚¯ã‚»ã‚¹ãƒˆãƒ¼ã‚¯ãƒ³ãŒæœŸé™åˆ‡ã‚Œã¾ãŸã¯æœŸé™åˆ‡ã‚Œé–“è¿‘ã§ã™ã€‚è‡ªå‹•ã§å†å–å¾—ã—ã¾ã™ã€‚")
            self._fetch_access_token()
            
    def _fetch_access_token(self):
        """å®Ÿéš›ã«ãƒˆãƒ¼ã‚¯ãƒ³ã‚’å–å¾—ã—ã€ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹å¤‰æ•°ã«ä¿å­˜ã™ã‚‹"""
        token_key = self._generate_token_key()
        
        headers = {
            'Authorization': f'Bearer {token_key}',
            'Content-Type': 'application/x-www-form-urlencoded',
        }
        data = {
            'grant_type': 'password',
            'scope': self.account_id
        }
        
        tqdm.write(f"ğŸ“¡ ã‚¢ã‚¯ã‚»ã‚¹ãƒˆãƒ¼ã‚¯ãƒ³ã‚’ {self.token_url} ã«ãƒªã‚¯ã‚¨ã‚¹ãƒˆä¸­...")

        try:
            response = requests.post(self.token_url, headers=headers, data=data)
            response.raise_for_status()
            
            token_data = response.json()
            new_token = token_data.get('access_token')
            expires_in = token_data.get('expires_in', 3600) # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ60åˆ†
            
            if new_token:
                self.access_token = new_token
                # ğŸ’¡ æœ‰åŠ¹æœŸé™æ™‚åˆ»ã‚’ UTC ã§è¨ˆç®—ã—ã¦ä¿å­˜
                self.token_expiry_time = datetime.now(timezone.utc) + timedelta(seconds=expires_in)
                tqdm.write(f"âœ… ã‚¢ã‚¯ã‚»ã‚¹ãƒˆãƒ¼ã‚¯ãƒ³å–å¾—æˆåŠŸã€‚æœ‰åŠ¹æœŸé™: {expires_in} ç§’ ({self.token_expiry_time.strftime('%Y-%m-%d %H:%M:%S')} UTC)")
            else:
                tqdm.write(f"âŒ ã‚¢ã‚¯ã‚»ã‚¹ãƒˆãƒ¼ã‚¯ãƒ³å–å¾—å¤±æ•—ã€‚ãƒ¬ã‚¹ãƒãƒ³ã‚¹: {token_data}")
                raise Exception("ã‚¢ã‚¯ã‚»ã‚¹ãƒˆãƒ¼ã‚¯ãƒ³ãŒãƒ¬ã‚¹ãƒãƒ³ã‚¹ã«å«ã¾ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
                
        except requests.exceptions.RequestException as e:
            tqdm.write(f"âŒ ã‚¢ã‚¯ã‚»ã‚¹ãƒˆãƒ¼ã‚¯ãƒ³ãƒªã‚¯ã‚¨ã‚¹ãƒˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
            raise

    def get_access_token(self):
        if not self.access_token:
            self._fetch_access_token()
            
    # --- åºƒå‘Šä¸»ä¸€è¦§å–å¾—ãƒ¡ã‚½ãƒƒãƒ‰ (get_advertiser_list / _parse_advertiser_xml) ---
    def get_advertiser_list(self):
        self.refresh_token_if_expired() 

        endpoint = urljoin(self.BASE_URL, 'advertisersearch/1.0')
        headers = {
            'Authorization': f'Bearer {self.access_token}',
        }
        
        tqdm.write(f"ğŸ“¡ åºƒå‘Šä¸»ä¸€è¦§ã‚’ {endpoint} ã«ãƒªã‚¯ã‚¨ã‚¹ãƒˆä¸­...")

        try:
            response = requests.get(endpoint, headers=headers)
            response.raise_for_status()
            return self._parse_advertiser_xml(response.text)

        except requests.exceptions.RequestException as e:
            tqdm.write(f"âŒ åºƒå‘Šä¸»ä¸€è¦§ãƒªã‚¯ã‚¨ã‚¹ãƒˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
            return []
            
    def _parse_advertiser_xml(self, xml_string):
        advertisers = []
        try:
            root = ET.fromstring(xml_string)
            for merchant_elem in root.findall('.//merchant'):
                mid = merchant_elem.find('mid').text if merchant_elem.find('mid') is not None else 'N/A'
                name = merchant_elem.find('merchantname').text if merchant_elem.find('merchantname') is not None else 'N/A'
                advertisers.append({'mid': mid, 'merchantname': name})
            return advertisers
        except ET.ParseError as e:
            tqdm.write(f"âŒ XMLãƒ‘ãƒ¼ã‚¹ã‚¨ãƒ©ãƒ¼: {e}")
            return []
    
    # ----------------------------------------------------------------------------------
    # ãƒšãƒ¼ã‚¸ãƒãƒ¼ã‚·ãƒ§ãƒ³ã¨XMLãƒ‘ãƒ¼ã‚¹ (å•†å“æ¤œç´¢é–¢é€£)
    # ----------------------------------------------------------------------------------
            
    def _extract_item_data(self, item_elem: ET.Element) -> dict:
        """å˜ä¸€ã® <item> è¦ç´ ã‹ã‚‰å¿…è¦ãªãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’æŠ½å‡ºã—ã¦è¾æ›¸å½¢å¼ã§è¿”ã™"""
        
        # ã‚«ãƒ†ã‚´ãƒªã®å‡¦ç†: <category><primary>ã¨<secondary>ã‚’çµåˆ
        category_elem = item_elem.find('category')
        primary_cat = category_elem.findtext('primary') if category_elem is not None else ''
        secondary_cat = category_elem.findtext('secondary') if category_elem is not None else ''
        full_category = f"{primary_cat}~~{secondary_cat}".strip("~~")

        # ä¾¡æ ¼ã®å‡¦ç†: é€šè²¨å±æ€§ã‚‚æŠ½å‡º
        price_elem = item_elem.find('price')
        sale_price_elem = item_elem.find('saleprice')

        # å•†å“æƒ…å ±è¾æ›¸ã‚’æ§‹ç¯‰ï¼ˆFTPå½¢å¼ã«è¿‘ã¥ã‘ã‚‹ï¼‰
        product_data = {
            'mid': item_elem.findtext('mid'),
            'merchantname': item_elem.findtext('merchantname'),
            'linkid': item_elem.findtext('linkid'),
            'createdon': item_elem.findtext('createdon'),
            'sku': item_elem.findtext('sku'),
            'productname': item_elem.findtext('productname').strip() if item_elem.findtext('productname') else 'N/A',
            'category': full_category,
            'price': {
                'value': price_elem.text,
                'currency': price_elem.get('currency')
            } if price_elem is not None else None,
            'saleprice': {
                'value': sale_price_elem.text,
                'currency': sale_price_elem.get('currency')
            } if sale_price_elem is not None else None,
            'upccode': item_elem.findtext('upccode'),
            'description_short': item_elem.findtext('description/short'),
            'description_long': item_elem.findtext('description/long'),
            'keywords': item_elem.findtext('keywords'),
            'linkurl': item_elem.findtext('linkurl'),
            'imageurl': item_elem.findtext('imageurl'),
        }
        return product_data

    def _fetch_product_page(self, params: dict) -> tuple[dict, int, int]:
        """
        å•†å“æ¤œç´¢APIã®å˜ä¸€ãƒšãƒ¼ã‚¸ã‚’ãƒ•ã‚§ãƒƒãƒã—ã€ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã¨å•†å“ãƒªã‚¹ãƒˆã‚’å«ã‚€è¾æ›¸ã‚’è¿”ã™
        """
        self.refresh_token_if_expired() 

        endpoint = urljoin(self.BASE_URL, 'productsearch/1.0')
        headers = {'Authorization': f'Bearer {self.access_token}'}
        url_with_params = f"{endpoint}?{urlencode(params)}"
        
        response = None
        try:
            response = requests.get(url_with_params, headers=headers)
            response.raise_for_status()
            
            root = ET.fromstring(response.text)
            
            # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º
            total_matches = int(root.findtext('TotalMatches') or 0)
            total_pages = int(root.findtext('TotalPages') or 0)
            
            # ã‚¢ã‚¤ãƒ†ãƒ ãƒªã‚¹ãƒˆã‚’æ§‹ç¯‰
            product_items = [
                self._extract_item_data(item_elem)
                for item_elem in root.findall('.//item')
            ]
            
            # ãƒšãƒ¼ã‚¸ã®çµæœè¾æ›¸ã‚’æ§‹ç¯‰
            page_result = {
                'TotalMatches': total_matches,
                'TotalPages': total_pages,
                'PageNumber': int(root.findtext('PageNumber') or 1),
                'items': product_items
            }
            
            return page_result, total_matches, total_pages

        except requests.exceptions.RequestException as e:
            tqdm.write(f"âŒ å•†å“æ¤œç´¢ãƒªã‚¯ã‚¨ã‚¹ãƒˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
            if response is not None and response.text:
                 tqdm.write(f"APIãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚¨ãƒ©ãƒ¼è©³ç´°:\n{response.text}")
            return {}, 0, 0
        except ET.ParseError as e:
            tqdm.write(f"âŒ XMLãƒ‘ãƒ¼ã‚¹ã‚¨ãƒ©ãƒ¼: {e}")
            return {}, 0, 0
            
    def search_products(self, keyword: str = None, mid: str = None, cat: str = None, page_size: int = 100, max_pages: int = 0) -> list[dict]:
        """
        å•†å“æ¤œç´¢APIã‚’åˆ©ç”¨ã—ã¦ã€å…¨ãƒšãƒ¼ã‚¸ã®å•†å“æƒ…å ±ã‚’å–å¾—ã—ã€JSONå½¢å¼ã®ç”Ÿãƒ‡ãƒ¼ã‚¿ãƒªã‚¹ãƒˆã‚’è¿”ã™
        """
        all_page_results = []
        page_size = min(page_size, 100)
        
        # æœ€åˆã®ãƒšãƒ¼ã‚¸ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        initial_params = {
            'max': page_size,
            'pagenumber': 1
        }
        # æ¤œç´¢æ¡ä»¶ã®è¿½åŠ 
        if keyword: initial_params['keyword'] = keyword
        if mid: initial_params['mid'] = mid
        if cat: initial_params['cat'] = cat
        
        # æ¤œç´¢æ¡ä»¶ãŒãªã„å ´åˆã¯ã‚¨ãƒ©ãƒ¼
        if not (keyword or mid or cat):
            raise ValueError("æ¤œç´¢ã«ã¯ã€keyword, mid, cat ã®ã†ã¡å°‘ãªãã¨ã‚‚1ã¤ã‚’æŒ‡å®šã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚")

        # 1ãƒšãƒ¼ã‚¸ç›®ã‚’ãƒ•ã‚§ãƒƒãƒ
        page_result_1, total_matches, total_pages = self._fetch_product_page(initial_params)
        
        if total_matches == 0:
            return []

        mid_for_log = mid or "ALL"
        
        # 1ãƒšãƒ¼ã‚¸ç›®ã®çµæœã‚’æ ¼ç´
        all_page_results.append(page_result_1)
        
        # å–å¾—ã™ã‚‹æœ€å¤§ãƒšãƒ¼ã‚¸æ•°ã‚’æ±ºå®š
        pages_to_fetch = min(total_pages, max_pages) if max_pages > 0 else total_pages
        
        tqdm.write(f"âœ… MID {mid_for_log} åˆè¨ˆ {total_matches} ä»¶ã€å…¨ {total_pages} ãƒšãƒ¼ã‚¸ã®å•†å“ãŒãƒ’ãƒƒãƒˆã—ã¾ã—ãŸã€‚")
        
        # 2ãƒšãƒ¼ã‚¸ç›®ä»¥é™ã‚’ãƒ«ãƒ¼ãƒ—ã§ãƒ•ã‚§ãƒƒãƒ
        if pages_to_fetch > 1:
            
            page_range = range(2, pages_to_fetch + 1)
            
            # ãƒšãƒ¼ã‚¸å–å¾—ãƒ«ãƒ¼ãƒ—ã‚’ tqdm ã§ãƒ©ãƒƒãƒ—
            for page in tqdm(page_range, desc=f"ğŸ“š MID {mid_for_log} ãƒšãƒ¼ã‚¸å–å¾—", unit="ãƒšãƒ¼ã‚¸"):
                
                loop_params = initial_params.copy()
                loop_params['pagenumber'] = page
                
                # APIãƒªã‚¯ã‚¨ã‚¹ãƒˆã®å®Ÿè¡Œ
                page_result_n, _, _ = self._fetch_product_page(loop_params)
                
                if page_result_n.get('items'):
                    all_page_results.append(page_result_n)
                else:
                    pass 
                
                if not page_result_n:
                    tqdm.write(f"âš ï¸ ãƒšãƒ¼ã‚¸ {page} ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸã€‚ã“ã®MIDã®ãƒšãƒ¼ã‚¸ãƒ³ã‚°ã‚’ä¸­æ–­ã—ã¾ã™ã€‚")
                    break

        # å–å¾—ã—ãŸå…¨ãƒšãƒ¼ã‚¸ã®çµæœãƒªã‚¹ãƒˆã‚’è¿”ã™
        tqdm.write(f"âœ… MID {mid_for_log} ã®å…¨ {len(all_page_results)} ãƒšãƒ¼ã‚¸ã®çµæœã‚’åé›†å®Œäº†ã—ã¾ã—ãŸã€‚")
        return all_page_results