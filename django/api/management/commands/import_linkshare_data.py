import os
import re
import ftplib
import time
import gzip
import csv
import traceback
import sys
import subprocess # â˜…â˜…â˜… è¿½åŠ : gunzipå®Ÿè¡Œç”¨
from datetime import datetime, timezone
from typing import List, Tuple, Dict, Any, Optional
from decimal import Decimal, InvalidOperation

# Djangoã®ã‚³ã‚¢æ©Ÿèƒ½ã¨ãƒ¢ãƒ‡ãƒ«ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from django.core.management.base import BaseCommand
from django.db import transaction, IntegrityError
from django.utils import timezone

# apiã‚¢ãƒ—ãƒªã®ãƒ¢ãƒ‡ãƒ«ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
# NOTE: ãƒ¢ãƒ‡ãƒ«ã®å®Ÿéš›ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆã¯ç’°å¢ƒã«ã‚ˆã‚Šç•°ãªã‚‹ãŸã‚ã€ã“ã“ã§ã¯ãƒ€ãƒŸãƒ¼ãƒ¢ãƒ‡ãƒ«ã¨ã—ã¦å®šç¾©ã—ã¾ã™ã€‚
class LinkshareProduct:
    @staticmethod
    def objects():
        class DummyManager:
            def update_or_create(self, merchant_id, sku, defaults):
                return (None, True)
        return DummyManager()
class RawApiData:
    pass


# ==============================================================================
# æ¥ç¶šãƒ»ãƒ•ã‚¡ã‚¤ãƒ«è¨­å®š (å®šæ•°)
# ==============================================================================
FTP_HOST = os.getenv("LINKSHARE_FTP_HOST", "aftp.linksynergy.com")
FTP_USER = os.getenv("LINKSHARE_BS_USER", "rkp_3750988")
FTP_PASS = os.getenv("LINKSHARE_BS_PASS", "u5NetPVZEAhABD7HuW2VRymP")
FTP_PORT = 21
FTP_TIMEOUT = 180

MAX_SIZE_BYTES = 1073741824 # 1 GB ã®ãƒã‚¤ãƒˆå€¤
# â˜…â˜…â˜… ä¿®æ­£: ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ã‚³ãƒ³ãƒ†ãƒŠå†…éƒ¨ã®ä¸€æ™‚çš„ãªå ´æ‰€ã«è¨­å®š â˜…â˜…â˜…
DOWNLOAD_DIR = "/tmp/ftp_downloads"

FULL_DATA_PATTERN = r"(\d+)_3750988_mp\.txt\.gz$"
DELTA_DATA_PATTERN = r"(\d+)_3750988_delta\.txt\.gz$"

# â˜…â˜…â˜… ãƒ‡ãƒªãƒŸã‚¿ã‚’ãƒ‘ã‚¤ãƒ—ã«å›ºå®š â˜…â˜…â˜…
FIXED_DELIMITER = '|'
FIXED_DELIMITER_NAME = 'PIPE'

# ==============================================================================
# ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°ç¾¤ (ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ã€ãƒ‡ãƒ¼ã‚¿å‹å¤‰æ›ã€FTPæ¥ç¶š)
# ==============================================================================

def human_readable_size(size_bytes):
    """ãƒã‚¤ãƒˆå˜ä½ã®ã‚µã‚¤ã‚ºã‚’KB, MB, GBã«å¤‰æ›ã—ã¦è¡¨ç¤ºã™ã‚‹"""
    if size_bytes is None or size_bytes == 0:
        return "0 B"
    size_name = ("B", "KB", "MB", "GB", "TB")
    i = 0
    size_bytes = float(size_bytes)
    while size_bytes >= 1024 and i < len(size_name) - 1:
        size_bytes /= 1024
        i += 1
    return f"{size_bytes:,.2f} {size_name[i]}"

def _get_ftp_client() -> Optional[ftplib.FTP]:
    """FTPã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’åˆæœŸåŒ–ã—ã€æ¥ç¶šãƒ»ãƒ­ã‚°ã‚¤ãƒ³ã‚’è©¦è¡Œã™ã‚‹"""
    if not all([FTP_HOST, FTP_USER, FTP_PASS]):
        print("ğŸš¨ [DEBUG] æ¥ç¶šæƒ…å ±ãŒä¸è¶³ã—ã¦ã„ã¾ã™ã€‚", file=sys.stderr, flush=True)
        return None

    ftp_client = None
    try:
        # æ¥ç¶šè©¦è¡Œãƒ­ã‚°
        print(f"ğŸ“¡ [DEBUG] æ¥ç¶šè©¦è¡Œ: {FTP_HOST}:{FTP_PORT}, ãƒ¦ãƒ¼ã‚¶ãƒ¼: {FTP_USER}")

        ftp_client = ftplib.FTP(timeout=FTP_TIMEOUT)
        ftp_client.connect(FTP_HOST, FTP_PORT)
        ftp_client.login(FTP_USER, FTP_PASS)

        print("âœ… [DEBUG] FTPæ¥ç¶šãŠã‚ˆã³ãƒ­ã‚°ã‚¤ãƒ³æˆåŠŸã€‚")
        return ftp_client

    except ftplib.all_errors as e:
        # FTPæ¥ç¶š/ãƒ­ã‚°ã‚¤ãƒ³å¤±æ•—æ™‚ã®ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°
        print(f"âŒ [DEBUG] FTPæ¥ç¶š/ãƒ­ã‚°ã‚¤ãƒ³å¤±æ•— (ftplib.all_errors): {type(e).__name__} - {e}", file=sys.stderr, flush=True)
        if ftp_client:
            try: ftp_client.quit()
            except Exception: pass
        return None
    except Exception as e:
        # ãã®ä»–ã®äºˆæœŸã›ã¬æ¥ç¶šã‚¨ãƒ©ãƒ¼ãƒ­ã‚°
        print(f"âŒ [DEBUG] FTPæ¥ç¶š/ãƒ­ã‚°ã‚¤ãƒ³å¤±æ•— (äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼): {type(e).__name__} - {e}", file=sys.stderr, flush=True)
        return None

def get_ftp_mid_list(data_path: str = "") -> List[Tuple[str, str, str, Optional[datetime], int]]:
    """FTPã‚µãƒ¼ãƒãƒ¼ã‹ã‚‰MIDãƒªã‚¹ãƒˆã‚’å–å¾—ã—ã€1GBè¶…ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã™ã‚‹ã€‚"""
    ftp = _get_ftp_client()
    if not ftp:
        return []

    if data_path:
        try:
            ftp.cwd(data_path)
            print(f"ğŸ“ [DEBUG] ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå¤‰æ›´: {data_path}")
        except ftplib.error_perm as e:
            print(f"âŒ [DEBUG] ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå¤‰æ›´å¤±æ•— (Error): {e}", file=sys.stderr, flush=True)
            ftp.quit()
            return []
        except Exception as e:
            print(f"âŒ [DEBUG] ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå¤‰æ›´å¤±æ•— (Unexpected Error): {e}", file=sys.stderr, flush=True)
            ftp.quit()
            return []

    try:
        file_names = ftp.nlst()
        print(f"ğŸ“‹ [DEBUG] ãƒ•ã‚¡ã‚¤ãƒ«ãƒªã‚¹ãƒˆå–å¾—æˆåŠŸã€‚ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {len(file_names)}")
    except Exception as e:
        print(f"âŒ [DEBUG] ãƒ•ã‚¡ã‚¤ãƒ«ãƒªã‚¹ãƒˆå–å¾—å¤±æ•—: {e}", file=sys.stderr, flush=True)
        ftp.quit()
        return []

    ftp.voidcmd('TYPE I')

    mid_file_details: Dict[str, Tuple[str, str, float, int]] = {}

    for filename in file_names:
        match_full = re.match(FULL_DATA_PATTERN, filename)
        match_delta = re.match(DELTA_DATA_PATTERN, filename)
        match = match_full or match_delta

        if not match:
            continue

        current_id = match.group(1)
        file_type = "FULL" if match_full else "DELTA"
        mtime_ts: float = 0.0
        file_size: int = 0

        try:
            file_size = ftp.size(filename)
            # â˜…â˜…â˜… 1GBè¶…ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã“ã“ã§ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚° â˜…â˜…â˜…
            if file_size > MAX_SIZE_BYTES:
                continue
        except Exception:
            continue

        # MDTM (ãƒ•ã‚¡ã‚¤ãƒ«æœ€çµ‚æ›´æ–°æ—¥æ™‚) ã‚’å–å¾—
        try:
            mtime_response = ftp.sendcmd('MDTM ' + filename)
            if mtime_response.startswith('213 '):
                mtime_str = mtime_response[4:].strip()
                mtime_dt_naive = datetime.strptime(mtime_str, '%Y%m%d%H%M%S')
                mtime_ts = mtime_dt_naive.replace(tzinfo=timezone.utc).timestamp()
        except Exception:
            pass

        # æ—¢å­˜ã®ãƒ•ã‚¡ã‚¤ãƒ«ã¨æ¯”è¼ƒã—ã€FULLãƒ•ã‚¡ã‚¤ãƒ«å„ªå…ˆ/æœ€æ–°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ®‹ã™ãƒ­ã‚¸ãƒƒã‚¯
        if current_id not in mid_file_details and mtime_ts > 0.0:
            mid_file_details[current_id] = (filename, file_type, mtime_ts, file_size)
        elif mtime_ts > 0.0:
            existing_filename, existing_type, existing_ts, existing_size = mid_file_details[current_id]
            if file_type == "FULL" and existing_type == "DELTA":
                mid_file_details[current_id] = (filename, file_type, mtime_ts, file_size)
            elif file_type == existing_type and mtime_ts > existing_ts:
                mid_file_details[current_id] = (filename, file_type, mtime_ts, file_size)

    try:
        ftp.quit()
    except Exception:
        pass

    final_list = []
    for current_id, details in mid_file_details.items():
        filename, file_type, mtime_ts, file_size = details
        mtime_dt = datetime.fromtimestamp(mtime_ts, tz=timezone.utc) if mtime_ts > 0.0 else None
        final_list.append((current_id, filename, file_type, mtime_dt, file_size))

    return sorted(final_list, key=lambda x: x[0])


def _parse_linkshare_date(date_str: Optional[str]) -> Optional[datetime]:
    """LinkShareã®æ—¥ä»˜ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ 'mm/dd/yyyy hh:mm:ss' ã‚’ãƒ‘ãƒ¼ã‚¹ã™ã‚‹"""
    if not date_str:
        return None
    try:
        return datetime.strptime(date_str, '%m/%d/%Y %H:%M:%S').replace(tzinfo=timezone.utc)
    except ValueError:
        return None

def _clean_decimal_field(value: Optional[str]) -> Optional[Decimal]:
    """é‡‘é¡ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã—ã€Decimalå‹ã«å¤‰æ›ã™ã‚‹"""
    if not value or not value.strip():
        return None
    try:
        cleaned_value = value.strip().replace(',', '')
        return Decimal(cleaned_value)
    except (InvalidOperation, ValueError):
        return None

# ==============================================================================
# ãƒ‡ãƒ¼ã‚¿ä¿å­˜ãƒ­ã‚¸ãƒƒã‚¯
# ==============================================================================

def _save_single_product(row_list: List[str], mid: str) -> Optional[LinkshareProduct]:
    """
    ãƒ‘ãƒ¼ã‚¹ã•ã‚ŒãŸå˜ä¸€ã®è¡Œãƒ‡ãƒ¼ã‚¿ (38ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰) ã‚’LinkshareProductãƒ¢ãƒ‡ãƒ«ã«ä¿å­˜ã™ã‚‹ã€‚
    """
    if len(row_list) != 38:
        return None

    sku = row_list[2].strip()
    if not sku:
        return None

    # ä¾¡æ ¼ã¨æ—¥ä»˜ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
    sale_price_dec = _clean_decimal_field(row_list[12])
    retail_price_dec = _clean_decimal_field(row_list[13])
    shipping_dec = _clean_decimal_field(row_list[17])
    discount_amount_dec = _clean_decimal_field(row_list[10])

    begin_date_dt = _parse_linkshare_date(row_list[14])
    end_date_dt = _parse_linkshare_date(row_list[15])

    try:
        # LinkshareProductã‚’SKUã¨MIDã‚’ã‚­ãƒ¼ã¨ã—ã¦æ›´æ–°ã¾ãŸã¯ä½œæˆ
        # ãƒ€ãƒŸãƒ¼å‡¦ç†
        return LinkshareProduct()

    except IntegrityError as e:
        print(f" Â âŒ DBã‚¨ãƒ©ãƒ¼ (MID: {mid}, SKU: {sku}): {e}", file=sys.stderr)
        return None
    except Exception as e:
        print(f" Â âŒ äºˆæœŸã›ã¬ä¿å­˜ã‚¨ãƒ©ãƒ¼ (MID: {mid}, SKU: {sku}): {e}", file=sys.stderr)
        return None

# ==============================================================================
# ãƒ‡ãƒ¼ã‚¿ãƒ‘ãƒ¼ã‚¹ã¨ä¿å­˜ã‚’çµ±åˆã—ãŸãƒ¡ã‚¤ãƒ³å‡¦ç†
# ==============================================================================

def parse_and_process_file(local_path: str, mid: str) -> Tuple[bool, int]:
    """
    ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ãŸãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ‘ãƒ¼ã‚¹ã—ã€å…¨ãƒ‡ãƒ¼ã‚¿è¡Œã‚’ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä¿å­˜ã™ã‚‹ã€‚
    gunzipã‚¯ãƒ©ãƒƒã‚·ãƒ¥ã‚’é¿ã‘ã‚‹ãŸã‚ã€subprocessã§gunzipã‚’å®Ÿè¡Œã—ã€è§£å‡æ¸ˆã¿ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€ã€‚
    """

    # 1. å‡¦ç†é–‹å§‹ãƒ‡ãƒãƒƒã‚°ãƒ­ã‚°ã‚’æ¨™æº–å‡ºåŠ›ã«å¼·åˆ¶å‡ºåŠ›
    print(f"ğŸ’¾ [DEBUG {mid}] STARTING PARSE: {os.path.basename(local_path)}.", file=sys.stdout, flush=True)

    delimiter = FIXED_DELIMITER
    delimiter_name = FIXED_DELIMITER_NAME
    encoding_list = ['utf-8', 'cp932', 'shift_jis', 'euc_jp']
    total_saved_rows = 0
    temp_local_path = local_path # å‡¦ç†å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã®åˆæœŸå€¤

    try:
        # â˜…â˜…â˜… ä¿®æ­£: GZIPãƒ•ã‚¡ã‚¤ãƒ«ã‚’äº‹å‰ã«gunzipã§è§£å‡ã™ã‚‹ãƒ–ãƒ­ãƒƒã‚¯ â˜…â˜…â˜…
        if local_path.endswith('.gz'):
            uncompressed_path = local_path[:-3] # .gzã‚’å‰Šé™¤ã—ãŸãƒ•ã‚¡ã‚¤ãƒ«å
            print(f"ğŸ”¥ [MID: {mid}] .gzãƒ•ã‚¡ã‚¤ãƒ«ã‚’gunzipã§äº‹å‰è§£å‡ä¸­... -> {os.path.basename(uncompressed_path)}", file=sys.stdout, flush=True)
            
            try:
                # gunzipã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œã—ã€æ¨™æº–å‡ºåŠ›ã‚’ã‚­ãƒ£ãƒ—ãƒãƒ£
                # -c: æ¨™æº–å‡ºåŠ›ã«æ›¸ãå‡ºã™, -f: å¼·åˆ¶ (ã»ã¨ã‚“ã©ä¸è¦ã ãŒå®‰å…¨ã®ãŸã‚)
                result = subprocess.run(
                    ['gunzip', '-c', local_path], 
                    capture_output=True, 
                    check=True # ã‚¼ãƒ­ä»¥å¤–ã®çµ‚äº†ã‚³ãƒ¼ãƒ‰ã§CalledProcessErrorã‚’ç™ºç”Ÿã•ã›ã‚‹
                )
                
                # è§£å‡ã•ã‚ŒãŸãƒã‚¤ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã«æ›¸ãè¾¼ã‚€ (ãƒã‚¤ãƒŠãƒªãƒ¢ãƒ¼ãƒ‰)
                with open(uncompressed_path, 'wb') as f:
                    f.write(result.stdout)
                
                # å‡¦ç†å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«ã‚’è§£å‡ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã«åˆ‡ã‚Šæ›¿ãˆã‚‹
                temp_local_path = uncompressed_path
                print(f"âœ… [MID: {mid}] äº‹å‰è§£å‡æˆåŠŸã€‚å‡¦ç†ãƒ•ã‚¡ã‚¤ãƒ«: {os.path.basename(temp_local_path)}", file=sys.stdout, flush=True)
                
            except subprocess.CalledProcessError as e:
                # gunzipã®å®Ÿè¡Œã«å¤±æ•—ã—ãŸå ´åˆ
                print(f"âŒ [MID: {mid}] gunzipè§£å‡ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚", file=sys.stderr, flush=True)
                print(f"Stderr: {e.stderr.decode('utf-8', errors='replace')}", file=sys.stderr, flush=True)
                return False, 0
            except Exception as e:
                # ãã®ä»–ã®I/Oã‚¨ãƒ©ãƒ¼ãªã©
                print(f"âŒ [MID: {mid}] äº‹å‰è§£å‡æ™‚ã«äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {type(e).__name__} - {e}", file=sys.stderr, flush=True)
                return False, 0
        
        # --- ã“ã“ã‹ã‚‰é€šå¸¸ã®ãƒ‘ãƒ¼ã‚¹å‡¦ç† (open() ã‚’ä½¿ç”¨) ---

        for encoding in encoding_list:
            try:
                processed_rows = 0
                is_likely_delimiter = False
                
                # 2. ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é€šå¸¸ã® open() ã§é–‹ãã€ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã¨ãƒ‡ãƒªãƒŸã‚¿ã‚’æ¤œè¨¼
                print(f"ğŸ” [DEBUG {mid}] è©¦è¡Œé–‹å§‹ (ENC: {encoding}): OPENING {os.path.basename(temp_local_path)}", file=sys.stdout, flush=True)

                # ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ†ã‚­ã‚¹ãƒˆãƒ¢ãƒ¼ãƒ‰ã§é–‹ã
                with open(temp_local_path, 'r', encoding=encoding, errors='replace') as f_text_test:
                    
                    # æœ€åˆã®50è¡Œã‚’æ¤œè¨¼
                    sample_lines: List[str] = []
                    for _ in range(50):
                        line = f_text_test.readline()
                        if not line: break
                        sample_lines.append(line)
                    
                    if not sample_lines:
                        # ãƒ•ã‚¡ã‚¤ãƒ«ãŒç©ºã®å ´åˆ
                        continue

                    # ãƒ˜ãƒƒãƒ€ãƒ¼è¡Œã‚’æ¤œè¨¼ï¼ˆ'|' åŒºåˆ‡ã‚Šã§38ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚ã‚‹ã‹ï¼‰
                    header_line = sample_lines[0].strip()
                    if header_line.startswith('HDR'):
                        header_fields = header_line.split(delimiter)
                        if len(header_fields) == 4 and header_fields[0] == 'HDR':
                             # 2è¡Œç›®ä»¥é™ã®ãƒ‡ãƒ¼ã‚¿è¡Œã‚’æ¤œè¨¼
                            valid_data_lines = 0
                            for line in sample_lines[1:]:
                                fields = line.strip().split(delimiter)
                                # ãƒ‡ãƒ¼ã‚¿è¡Œã¯38ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰
                                if len(fields) == 38: 
                                    is_likely_delimiter = True
                                    valid_data_lines += 1
                                    # LinkID (1ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ç›®) ãŒæ•°å€¤ã§ã‚ã‚‹ã“ã¨ã‚’ç¢ºèª
                                    try:
                                        int(fields[0].strip())
                                    except ValueError:
                                        is_likely_delimiter = False
                                        break
                                
                                if valid_data_lines >= 5: # 5è¡Œä»¥ä¸Šæ­£å¸¸ãªã‚‰OKã¨ã™ã‚‹
                                    break
                            
                            if is_likely_delimiter:
                                print(f"ğŸ” [DEBUG {mid}] æ—©æœŸæ¤œè¨¼æˆåŠŸ: ENC: {encoding}, DELIM: {delimiter_name}", file=sys.stdout, flush=True)

                
                if not is_likely_delimiter:
                    print(f" Â âŒ [DEBUG {mid}] æ—©æœŸæ¤œè¨¼å¤±æ•— (ENC: {encoding}): ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰æ•°ãŒä¸æ­£ (38ä»¥å¤–) ã¾ãŸã¯ LinkIDãŒæ•°å€¤ã§ãªã„ã€‚", file=sys.stdout, flush=True)
                    continue

                print(f" Â â¡ï¸ [MID: {mid}] è©¦è¡Œ: ENC: {encoding}, DELIM: {delimiter_name}ã€‚æœ¬ç•ªãƒ‘ãƒ¼ã‚¹é–‹å§‹...", file=sys.stdout, flush=True)

                # â˜…â˜…â˜… æœ¬ç•ªãƒ‘ãƒ¼ã‚¹: æˆåŠŸã—ãŸã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã§ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å†åº¦é–‹ãã€CSVãƒªãƒ¼ãƒ€ãƒ¼ã§å‡¦ç† â˜…â˜…â˜…
                with open(temp_local_path, 'r', encoding=encoding, errors='replace') as f_main:
                    # ãƒ˜ãƒƒãƒ€ãƒ¼è¡Œ (HDR) ã‚’ã‚¹ã‚­ãƒƒãƒ—
                    f_main.readline() 
                    
                    csv_reader = csv.reader(f_main, delimiter=delimiter, quotechar='"')
                    
                    for row in csv_reader:
                        if not row or len(row) == 1 and not row[0].strip():
                            continue # ç©ºè¡Œã‚’ã‚¹ã‚­ãƒƒãƒ—
                        
                        # 38ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚ã‚‹ã“ã¨ã‚’ç¢ºèª
                        if len(row) == 38:
                            # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ä¿å­˜å‡¦ç†
                            _save_single_product(row, mid)
                            processed_rows += 1
                        
                        if processed_rows % 10000 == 0 and processed_rows > 0:
                            print(f" Â ğŸ”„ [MID: {mid}] å‡¦ç†ä¸­... {processed_rows:,} è¡Œ", file=sys.stdout, flush=True)
                
                total_saved_rows = processed_rows
                
                # å‡¦ç†ã«æˆåŠŸã—ãŸã‚‰ãƒ«ãƒ¼ãƒ—ã‚’æŠœã‘ã‚‹
                print(f"âœ… [MID: {mid}] æ­£å¸¸ã«å‡¦ç†ã‚’å®Œäº†ã—ã¾ã—ãŸã€‚æœ€çµ‚è¡Œæ•°: {total_saved_rows:,}", file=sys.stdout, flush=True)
                return True, total_saved_rows

            except Exception as e:
                # ãƒ‡ã‚³ãƒ¼ãƒ‰/CSVèª­ã¿å–ã‚Šã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãŸå ´åˆã€æ¬¡ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚’è©¦è¡Œ
                print(f" Â âŒ è©¦è¡Œå¤±æ•— (ENC: {encoding}, DELIM: {delimiter_name}): {type(e).__name__} - {e}", file=sys.stdout, flush=True)
                pass

        print(f" Â âš ï¸ [MID: {mid}] å…¨ã¦ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°è©¦è¡Œã§ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ã¾ãŸã¯ä¿å­˜ã«å¤±æ•—ã—ã¾ã—ãŸã€‚", file=sys.stdout, flush=True)
        return False, 0

    except Exception as fatal_e:
        # è‡´å‘½çš„ãªã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãŸå ´åˆã€æ¨™æº–å‡ºåŠ›ã«å¼·åˆ¶çš„ã«ãƒˆãƒ¬ãƒ¼ã‚¹ãƒãƒƒã‚¯ã‚’å‡ºåŠ›
        print(f"âŒ [MID: {mid}] å‡¦ç†ä¸­ã«è‡´å‘½çš„ãªã‚¯ãƒ©ãƒƒã‚·ãƒ¥ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚åŸå› ä¸æ˜ã®å ´æ‰€ã§ã®ã‚¨ãƒ©ãƒ¼ã€‚", file=sys.stdout, flush=True)
        print("--- FATAL ERROR TRACEBACK START ---", file=sys.stdout, flush=True)
        traceback.print_exc(file=sys.stdout) # æ¨™æº–å‡ºåŠ›ã«ãƒˆãƒ¬ãƒ¼ã‚¹ãƒãƒƒã‚¯ã‚’å‡ºåŠ›
        print("--- FATAL ERROR TRACEBACK END ---", file=sys.stdout, flush=True)
        return False, 0

    finally:
        # ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤å‡¦ç†
        try:
            # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ãŸãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆ.gzï¼‰ã‚’å‰Šé™¤
            if os.path.exists(local_path):
                os.remove(local_path)
            
            # äº‹å‰è§£å‡ã—ãŸãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆ.txtï¼‰ã‚‚å‰Šé™¤
            if local_path.endswith('.gz'):
                uncompressed_path = local_path[:-3]
                if os.path.exists(uncompressed_path):
                    os.remove(uncompressed_path)

        except Exception as e:
            # ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤å¤±æ•—ãƒ­ã‚°ã‚‚æ¨™æº–å‡ºåŠ›ã«å¼·åˆ¶å‡ºåŠ›
            print(f"âš ï¸ [MID: {mid}] ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤ã«å¤±æ•—ã—ã¾ã—ãŸ: {local_path} / {temp_local_path} ({e})", file=sys.stdout, flush=True)

# ==============================================================================
# ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰æ©Ÿèƒ½
# ==============================================================================

class DownloadProgress:
    """ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰é€²æ—ã‚’ç®¡ç†ã—ã€ãƒ•ã‚¡ã‚¤ãƒ«æ›¸ãè¾¼ã¿ã‚’è¡Œã†ã‚¯ãƒ©ã‚¹"""
    def __init__(self, total_size: int, file_pointer: Any):
        self.total_size = total_size
        self.downloaded = 0
        self.start_time = time.time()
        self.last_print_len = 0
        self.file_pointer = file_pointer

    def update(self, data: bytes):
        """ãƒ‡ãƒ¼ã‚¿ãƒãƒ£ãƒ³ã‚¯ã‚’å—ä¿¡ã™ã‚‹ãŸã³ã«å‘¼ã³å‡ºã•ã‚Œã€é€²æ—ã‚’æ›´æ–°ãƒ»è¡¨ç¤ºã—ã€ãƒ•ã‚¡ã‚¤ãƒ«ã«æ›¸ãè¾¼ã‚€"""
        self.file_pointer.write(data)
        self.downloaded += len(data)

        # 1MBã”ã¨ã«é€²æ—è¡¨ç¤ºã‚’æ›´æ–°
        if self.downloaded % (1024 * 1024) == 0 or self.downloaded == self.total_size:
            percent = (self.downloaded / self.total_size) * 100
            elapsed = time.time() - self.start_time
            speed = (self.downloaded / elapsed) if elapsed > 0 else 0

            progress_str = (
                f"ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ä¸­: {human_readable_size(self.downloaded)} "
                f"/ {human_readable_size(self.total_size)} "
                f"({percent:3.1f}%) "
                f"é€Ÿåº¦: {human_readable_size(speed).replace(' B', 'B/s')}"
            )
            # å¤ã„è¡Œã‚’ã‚¹ãƒšãƒ¼ã‚¹ã§ä¸Šæ›¸ãã›ãšã€ã‚­ãƒ£ãƒªãƒƒã‚¸ãƒªã‚¿ãƒ¼ãƒ³ã§æ›´æ–°
            print('\r' + progress_str, end='', flush=True)
            self.last_print_len = len(progress_str)

def download_file(filename: str, local_path: str, file_size: int, mid: str) -> Tuple[bool, int]:
    """FTPã‹ã‚‰ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã€é€²æ—ã‚’è¡¨ç¤ºã—ã€ãã®å¾Œãƒ‘ãƒ¼ã‚¹ãƒ»ä¿å­˜ã‚’è¡Œã†"""
    print(f"\nğŸ“¥ ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰é–‹å§‹: {filename} -> {local_path} ({human_readable_size(file_size)})")

    ftp = _get_ftp_client()
    if not ftp:
        print("âŒ FTPæ¥ç¶šã«å¤±æ•—ã—ã¾ã—ãŸã€‚ï¼ˆãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰é–‹å§‹å‰ï¼‰")
        return False, 0

    download_success = False
    downloaded_size = 0
    saved_rows = 0

    try:
        # download_fileå†…ã§ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆã¯ä¸è¦ï¼ˆhandleã§å®Ÿæ–½æ¸ˆã¿ï¼‰

        with open(local_path, 'wb') as fp:
            progress = DownloadProgress(file_size, fp)
            ftp.retrbinary(f'RETR {filename}', progress.update)
            downloaded_size = progress.downloaded

        print("\r" + " " * progress.last_print_len, end='', flush=True)
        print("\râœ… ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å®Œäº†ã€‚")
        download_success = True

    except ftplib.all_errors as e:
        print(f"\nâŒ ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ä¸­ã«FTPã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ (MID: {mid}): {type(e).__name__} - {e}", file=sys.stderr, flush=True)
    except Exception as e:
        print(f"\nâŒ äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ (MID: {mid}): {type(e).__name__} - {e}", file=sys.stderr, flush=True)
    finally:
        try:
            ftp.quit()
        except Exception:
            pass

    # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãŒæˆåŠŸã—ãŸå ´åˆã®ã¿ã€ãƒ‘ãƒ¼ã‚¹æ©Ÿèƒ½ã®å‘¼ã³å‡ºã—
    if download_success and downloaded_size == file_size:

        # ãƒ‘ãƒ¼ã‚¹ã¨ä¿å­˜å‡¦ç†ã‚’å®Ÿè¡Œ
        try:
            # â˜…â˜…â˜… ãƒ­ã‚°è¿½åŠ : parse_and_process_file å‘¼ã³å‡ºã—ç›´å‰ â˜…â˜…â˜…
            print(f"ğŸ‘‰ [DEBUG {mid}] PARSE_FUNC_CALL START", file=sys.stdout, flush=True) 

            success, saved_rows = parse_and_process_file(local_path, mid)
            
            # â˜…â˜…â˜… ãƒ­ã‚°è¿½åŠ : parse_and_process_file å‘¼ã³å‡ºã—ç›´å¾Œï¼ˆæˆåŠŸæ™‚ï¼‰ â˜…â˜…â˜…
            print(f"ğŸ‘ˆ [DEBUG {mid}] PARSE_FUNC_CALL END (Success: {success})", file=sys.stdout, flush=True)

            if success:
                return success, saved_rows

        except Exception as e:
            # download_fileå†…ã§æ•æ‰ã•ã‚ŒãŸè‡´å‘½çš„ã‚¯ãƒ©ãƒƒã‚·ãƒ¥ãƒ­ã‚°ã¯parse_and_process_fileå†…ã§å‡¦ç†ã•ã‚Œã‚‹
            pass

    return False, 0


# ==============================================================================
# Django Management Command ã®å®šç¾©
# ==============================================================================

class Command(BaseCommand):
    help = 'LinkShare FTPã‹ã‚‰ãƒãƒ¼ãƒãƒ£ãƒ³ãƒ€ã‚¤ã‚¶ãƒ¼ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã€LinkshareProductãƒ¢ãƒ‡ãƒ«ã«ã‚¤ãƒ³ãƒãƒ¼ãƒˆã—ã¾ã™ã€‚'

    def add_arguments(self, parser):
        parser.add_argument(
            '--mid',
            type=str,
            help='å‡¦ç†ã™ã‚‹ç‰¹å®šã®ãƒãƒ¼ãƒãƒ£ãƒ³ãƒˆID (MID) ã‚’æŒ‡å®šã—ã¾ã™ã€‚',
            default=None
        )
        parser.add_argument(
            '--limit',
            type=int,
            default=5,
            help='ãƒ†ã‚¹ãƒˆå®Ÿè¡Œã®ãŸã‚ã€å‡¦ç†ã™ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ã®æœ€å¤§æ•°ã‚’æŒ‡å®šã—ã¾ã™ (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 5)ã€‚'
        )

    def handle(self, *args, **options):
        self.stdout.write(self.style.SUCCESS("--- LinkShare ãƒ‡ãƒ¼ã‚¿ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚³ãƒãƒ³ãƒ‰é–‹å§‹ ---"))

        # â˜…â˜…â˜… ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®è‡ªå‹•ä½œæˆ â˜…â˜…â˜…
        if not os.path.exists(DOWNLOAD_DIR):
            try:
                os.makedirs(DOWNLOAD_DIR)
                self.stdout.write(self.style.SUCCESS(f"ğŸ“‚ ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª {DOWNLOAD_DIR} ã‚’ä½œæˆã—ã¾ã—ãŸã€‚"))
            except Exception as e:
                self.stderr.write(self.style.ERROR(f"ğŸš¨ ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ä½œæˆã«å¤±æ•—ã—ã¾ã—ãŸ: {DOWNLOAD_DIR} ({e})"))
                return

        target_mid = options['mid']
        limit = options['limit']

        # 1. FTPãƒ•ã‚¡ã‚¤ãƒ«ãƒªã‚¹ãƒˆã®å–å¾—
        self.stdout.write("ğŸ” FTPã‚µãƒ¼ãƒãƒ¼ã‹ã‚‰å‡¦ç†å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«ãƒªã‚¹ãƒˆã‚’å–å¾—ä¸­... (1GBæœªæº€ã®ãƒ•ã‚¡ã‚¤ãƒ«ã«é™å®š)")
        DATA_PATH = os.getenv("LINKSHARE_BS_DATA_PATH", "")

        try:
            mid_list = get_ftp_mid_list(DATA_PATH)
        except Exception as e:
            self.stderr.write(self.style.ERROR(f"FTPãƒ•ã‚¡ã‚¤ãƒ«ãƒªã‚¹ãƒˆå–å¾—ã‚¨ãƒ©ãƒ¼: {e}"))
            return

        # ãƒ•ã‚¡ã‚¤ãƒ«ãƒªã‚¹ãƒˆè¡¨ç¤ºãƒ­ã‚¸ãƒƒã‚¯
        if not mid_list:
            self.stdout.write(self.style.WARNING("å‡¦ç†å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚‰ãªã‹ã£ãŸã‹ã€FTPæ¥ç¶šã«å¤±æ•—ã—ã¾ã—ãŸã€‚"))
            return

        self.stdout.write(f"\nâœ… FTPã‹ã‚‰ä»¥ä¸‹ã® **{len(mid_list)}** ä»¶ã®å‡¦ç†å¯èƒ½ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸ (1GBæœªæº€):")

        # ãƒªã‚¹ãƒˆã‚’æ•´å½¢ã—ã¦è¡¨ç¤º
        self.stdout.write("-" * 80)
        self.stdout.write("{:<10} {:<10} {:<60}".format("MID", "ã‚µã‚¤ã‚º", "ãƒ•ã‚¡ã‚¤ãƒ«å"))
        self.stdout.write("{:<10} {:<10} {:<60}".format("-" * 3, "-" * 6, "-" * 60))

        for mid, filename, file_type, mtime_dt, file_size in mid_list:
            size_hr = human_readable_size(file_size)
            self.stdout.write("{:<10} {:<10} {:<60}".format(mid, size_hr, filename))

        self.stdout.write("-" * 80)

        # ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã¨åˆ¶é™
        if target_mid:
            mid_list = [item for item in mid_list if item[0] == target_mid]
            if not mid_list:
                self.stdout.write(self.style.WARNING(f"æŒ‡å®šã•ã‚ŒãŸMID ({target_mid}) ã«è©²å½“ã™ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚"))
                return

        files_to_process = mid_list[:limit]

        if not files_to_process:
            self.stdout.write(self.style.WARNING(f"åˆ¶é™æ•° ({limit}) ã«ã‚ˆã‚Šã€å‡¦ç†å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚Šã¾ã›ã‚“ã€‚"))
            return

        total_processed_files = 0
        total_saved_rows = 0

        self.stdout.write(f"\nğŸš€ ä¸Šä½ {len(files_to_process)} ä»¶ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¦å‡¦ç†ã—ã¾ã™ã€‚")

        # 2. ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã¨ãƒ‘ãƒ¼ã‚¹ã®å®Ÿè¡Œ
        with transaction.atomic():
            for mid, filename, file_type, _, file_size in files_to_process:
                local_file_path = os.path.join(DOWNLOAD_DIR, filename)

                success, saved_rows = download_file(filename, local_file_path, file_size, mid)

                if success:
                    total_processed_files += 1
                    total_saved_rows += saved_rows
                    self.stdout.write(self.style.SUCCESS(f"\n[MID: {mid}] å‡¦ç†å®Œäº†ã€‚DBä¿å­˜ä»¶æ•°: {saved_rows:,} ä»¶"))
                else:
                    self.stdout.write(self.style.ERROR(f"\n[MID: {mid}] å‡¦ç†å¤±æ•—ã€‚"))

        self.stdout.write(self.style.SUCCESS(f"\n--- ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚³ãƒãƒ³ãƒ‰å®Œäº†: {total_processed_files} / {len(files_to_process)} ä»¶ã®ãƒ•ã‚¡ã‚¤ãƒ«ãŒæ­£å¸¸ã«å‡¦ç†ã•ã‚Œã¾ã—ãŸ (åˆè¨ˆ {total_saved_rows:,} è¡Œä¿å­˜) ---"))