# -*- coding: utf-8 -*-
import logging
import re
from django.core.management.base import BaseCommand
from django.db import transaction, models
from django.db.models import Count, OuterRef, Subquery
from django.db.models.functions import Coalesce
from django.utils import timezone 

# é–¢é€£ãƒ¢ãƒ‡ãƒ«
from api.models import (
    RawApiData, AdultProduct, Genre, Actress, 
    Director, Maker, Label, Series
)

# ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£
from api.utils.adult.fanza_normalizer import normalize_fanza_data 
from api.utils.adult.entity_manager import get_or_create_entity 

logger = logging.getLogger('normalize_adult')

ENTITY_MODELS = [Maker, Label, Director, Series, Genre, Actress]
ENTITY_RELATION_KEYS = {
    Maker: 'maker', 
    Label: 'label', 
    Director: 'director', 
    Series: 'series',
    Genre: 'genres', 
    Actress: 'actresses'
}

class Command(BaseCommand):
    help = 'RawApiDataã‚’AdultProductã¸æ­£è¦åŒ–ã—ã€ãƒãƒƒãƒå†…é‡è¤‡ã‚’æ’é™¤ã—ã¦UPSERTã—ã¾ã™ã€‚'

    def add_arguments(self, parser):
        parser.add_argument('--limit', type=int, help='å‡¦ç†ä»¶æ•°åˆ¶é™')
        parser.add_argument('--source', type=str, default=None, help='FANZA or DMM')
        parser.add_argument('--re-run', action='store_true', help='migrated=Trueã®ãƒ‡ãƒ¼ã‚¿ã‚‚å†å‡¦ç†ã™ã‚‹')

    def _optimize_url(self, url):
        """DMM/FANZAã®URLã‚’æœ€é«˜ç”»è³ªã¸ç½®æ›"""
        if not url:
            return ""
        if url.startswith('//'):
            url = 'https:' + url
            
        if 'pics.dmm.com' in url or 'pics.dmm.co.jp' in url:
            # ps.jpg / pt.jpg -> pl.jpg
            url = re.sub(r'p[s|t]\.jpg', 'pl.jpg', url, flags=re.IGNORECASE)
            # _s.jpg / _m.jpg -> _l.jpg
            url = re.sub(r'_[ms]\.jpg', '_l.jpg', url, flags=re.IGNORECASE)
        return url

    def handle(self, *args, **options):
        sources = [options['source'].upper()] if options['source'] else ['FANZA', 'DMM']
        re_run = options.get('re_run', False)
        
        for source in sources:
            self.stdout.write(self.style.NOTICE(f'\n--- {source} æ­£è¦åŒ–ãƒ»é«˜ç”»è³ªåŒ–ãƒ•ã‚§ãƒ¼ã‚ºé–‹å§‹ ---'))
            
            filters = {'api_source': source}
            if not re_run:
                filters['migrated'] = False
                
            raw_qs = RawApiData.objects.filter(**filters).order_by('id')
            if options['limit']:
                raw_qs = raw_qs[:options['limit']]

            total = raw_qs.count()
            if total == 0:
                self.stdout.write(self.style.WARNING(f"{source} ã®å‡¦ç†å¯¾è±¡ãƒ‡ãƒ¼ã‚¿ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚"))
                continue

            batch_size = 500
            # ğŸš€ é‡è¤‡æ’é™¤ç”¨è¾æ›¸: product_id_uniqueã‚’ã‚­ãƒ¼ã«ã—ã¦æœ€æ–°ã®ãƒ‡ãƒ¼ã‚¿ã§ä¸Šæ›¸ãä¿æŒã™ã‚‹
            batch_dict = {} 
            batch_relations = {}
            processed_raw_ids = []

            for raw_instance in raw_qs:
                try:
                    # fanza_normalizer ã‹ã‚‰æ­£è¦åŒ–ãƒ‡ãƒ¼ã‚¿ã‚’å—ã‘å–ã‚‹
                    p_list, r_list = normalize_fanza_data(raw_instance)
                    if not p_list:
                        raw_instance.migrated = True
                        raw_instance.save(update_fields=['migrated'])
                        continue

                    # 1ã¤ã®Rawãƒ‡ãƒ¼ã‚¿ã‹ã‚‰è¤‡æ•°ã®å•†å“ãŒå‡ºã‚‹å¯èƒ½æ€§ã¯ã‚ã‚‹ãŒã€åŸºæœ¬ã¯1ä»¶ç›®ã‚’å‡¦ç†
                    p_data = p_list[0]
                    r_data = r_list[0]
                    unique_id = p_data['product_id_unique']

                    # ğŸš€ ç”»åƒURLãƒªã‚¹ãƒˆã®é«˜ç”»è³ªåŒ–
                    if 'image_url_list' in p_data and p_data['image_url_list']:
                        optimized_urls = [self._optimize_url(u) for u in p_data['image_url_list']]
                        # é‡è¤‡æ’é™¤ã¨ç©ºè¦ç´ ã®é™¤å»
                        p_data['image_url_list'] = list(dict.fromkeys(filter(None, optimized_urls)))

                    # ğŸ¥ å‹•ç”»ãƒ‡ãƒ¼ã‚¿ã®ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ç”»åƒã‚‚é«˜ç”»è³ªåŒ–
                    if isinstance(p_data.get('sample_movie_url'), dict):
                        preview = p_data['sample_movie_url'].get('preview_image')
                        if preview:
                            p_data['sample_movie_url']['preview_image'] = self._optimize_url(preview)

                    p_data['api_source'] = source
                    p_data['updated_at'] = timezone.now()

                    # ğŸš€ ãƒãƒƒãƒå†…é‡è¤‡æ’é™¤: 
                    # åŒã˜IDãŒæ¥ãŸå ´åˆã€å¾Œã‹ã‚‰æ¥ãŸï¼ˆæã‚‰ãæ–°ã—ã„ï¼‰RawApiDataã®å†…å®¹ã§è¾æ›¸ã‚’æ›´æ–°
                    batch_dict[unique_id] = p_data
                    batch_relations[unique_id] = r_data
                    processed_raw_ids.append(raw_instance.id)

                    # ãƒãƒƒãƒã‚µã‚¤ã‚ºã«é”ã—ãŸã‚‰æ›¸ãè¾¼ã¿
                    if len(batch_dict) >= batch_size:
                        self._process_batch(list(batch_dict.values()), batch_relations, processed_raw_ids, source)
                        batch_dict, batch_relations, processed_raw_ids = {}, {}, []

                except Exception as e:
                    self.stdout.write(self.style.ERROR(f"Raw ID {raw_instance.id} å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}"))
                    logger.exception(f"Error processing RawApiData {raw_instance.id}")

            # æ®‹ã‚Šã®ãƒãƒƒãƒã‚’å‡¦ç†
            if batch_dict:
                self._process_batch(list(batch_dict.values()), batch_relations, processed_raw_ids, source)

        # å…¨ã‚½ãƒ¼ã‚¹å®Œäº†å¾Œã«ã‚«ã‚¦ãƒ³ãƒˆæ›´æ–°
        self._update_all_product_counts()
        self.stdout.write(self.style.SUCCESS('\nâœ… FANZA/DMM å…¨å·¥ç¨‹ãŒå®Œäº†ã—ã¾ã—ãŸ'))

    def _process_batch(self, products_data, relations_map, raw_ids, source):
        """åå‰è§£æ±ºãƒ»UPSERTãƒ»M2Mæ›´æ–°ã‚’ä¸€æ‹¬å®Ÿè¡Œ"""
        
        # 1. ãƒã‚¹ã‚¿ãƒ¼ãƒ‡ãƒ¼ã‚¿ã®åå‰è§£æ±ºï¼ˆMaker, Label, Actressç­‰ï¼‰
        all_names = {M: set() for M in ENTITY_MODELS}
        for p in products_data:
            for M in [Maker, Label, Director, Series]:
                key = ENTITY_RELATION_KEYS[M]
                val = p.get(key)
                if val: all_names[M].add(val)
        
        for r in relations_map.values():
            for M in [Genre, Actress]:
                key = ENTITY_RELATION_KEYS[M]
                for name in r.get(key, []): 
                    if name: all_names[M].add(name)

        # Entityã‚’ä¸€æ‹¬å–å¾—ã¾ãŸã¯ä½œæˆã—ã€åå‰ã‹ã‚‰IDã¸ã®ãƒãƒƒãƒ—ã‚’ä½œæˆ
        pk_maps = {M: get_or_create_entity(M, list(names), source) for M, names in all_names.items() if names}

        # 2. FKï¼ˆå¤–éƒ¨ã‚­ãƒ¼ï¼‰ã®ç½®æ›ã¨ãƒ¢ãƒ‡ãƒ«ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹åŒ–
        upsert_list = []
        for p in products_data:
            # ä¸è¦ãªã‚­ãƒ¼ã‚’å‰Šé™¤ï¼ˆãƒ¢ãƒ‡ãƒ«ã®ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã«å­˜åœ¨ã—ãªã„ã‚‚ã®ï¼‰
            p.pop('image_url', None) 
            p.pop('raw_data_id', None)
            
            # å„Entityã®åå‰ã‚’IDã«å¤‰æ›ã—ã¦ã‚»ãƒƒãƒˆ
            for M in [Maker, Label, Director, Series]:
                key = ENTITY_RELATION_KEYS[M]
                name = p.pop(key, None)
                p[f'{key}_id'] = pk_maps.get(M, {}).get(name) if name else None
            
            # ãƒ¢ãƒ‡ãƒ«ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ãƒªã‚¹ãƒˆã«è¿½åŠ 
            upsert_list.append(AdultProduct(**p))

        # 3. ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã¸ã® UPSERT å®Ÿè¡Œ
        if not upsert_list:
            return

        with transaction.atomic():
            # unique_fields ãŒè¡çªã—ãŸéš›ã« update_fields ã‚’æ›´æ–°ã™ã‚‹
            AdultProduct.objects.bulk_create(
                upsert_list,
                update_conflicts=True,
                unique_fields=['product_id_unique'],
                update_fields=[
                    'title', 'affiliate_url', 'image_url_list', 
                    'sample_movie_url', 'price', 'release_date', 
                    'maker_id', 'label_id', 'director_id', 'series_id', 'updated_at'
                ]
            )

            # M2Mé–¢ä¿‚ï¼ˆã‚¸ãƒ£ãƒ³ãƒ«ã€å¥³å„ªï¼‰ã®åŒæœŸ
            # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹å´ã®æœ€æ–°ã®IDãƒãƒƒãƒ—ã‚’å–å¾—
            db_map = {obj.product_id_unique: obj.id for obj in AdultProduct.objects.filter(
                product_id_unique__in=[p.product_id_unique for p in upsert_list]
            )}

            for M in [Genre, Actress]:
                key = ENTITY_RELATION_KEYS[M]
                through_model = getattr(AdultProduct, key).through
                
                # ä¸€æ—¦ã€ã“ã®ãƒãƒƒãƒå†…ã®å•†å“ã«ç´ã¥ãM2Mã‚’å‰Šé™¤ï¼ˆãƒªãƒ•ãƒ¬ãƒƒã‚·ãƒ¥ï¼‰
                through_model.objects.filter(adultproduct_id__in=db_map.values()).delete()
                
                rels = []
                for unique_id, r in relations_map.items():
                    pid = db_map.get(unique_id)
                    m_map = pk_maps.get(M, {})
                    for name in r.get(key, []):
                        eid = m_map.get(name)
                        if pid and eid:
                            kwargs = {'adultproduct_id': pid, f'{M.__name__.lower()}_id': eid}
                            rels.append(through_model(**kwargs))
                
                if rels:
                    through_model.objects.bulk_create(rels, ignore_conflicts=True)

            # å‡¦ç†æ¸ˆã¿RawApiDataã®ãƒ•ãƒ©ã‚°æ›´æ–°
            RawApiData.objects.filter(id__in=raw_ids).update(migrated=True, updated_at=timezone.now())

    def _update_all_product_counts(self):
        """ãƒã‚¹ã‚¿ãƒ¼ãƒ‡ãƒ¼ã‚¿ï¼ˆå¥³å„ªã€ãƒ¡ãƒ¼ã‚«ãƒ¼ç­‰ï¼‰ã®ä½œå“æ•°ã‚«ã‚¦ãƒ³ãƒˆã‚’ä¸€æ‹¬æ›´æ–°"""
        self.stdout.write("å„ãƒã‚¹ã‚¿ãƒ¼ã®ä½œå“æ•°ã‚«ã‚¦ãƒ³ãƒˆã‚’æ›´æ–°ä¸­...")
        with transaction.atomic():
            MAPPING = [
                (Actress, 'actresses'), (Genre, 'genres'),
                (Maker, 'maker_id'), (Label, 'label_id'),
                (Director, 'director_id'), (Series, 'series_id'),
            ]
            for Model, field in MAPPING:
                if field.endswith('_id'):
                    # FKï¼ˆMakerç­‰ï¼‰ã®å ´åˆ
                    subq = AdultProduct.objects.filter(**{field: OuterRef('pk')}).values(field).annotate(c=Count('id')).values('c')[:1]
                else:
                    # M2Mï¼ˆActressç­‰ï¼‰ã®å ´åˆ
                    through = getattr(AdultProduct, field).through
                    fk = f"{Model.__name__.lower()}_id"
                    subq = through.objects.filter(**{fk: OuterRef('pk')}).values(fk).annotate(c=Count('adultproduct_id')).values('c')[:1]
                
                Model.objects.update(product_count=Coalesce(Subquery(subq, output_field=models.IntegerField()), 0))