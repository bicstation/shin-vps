import os
import re
import ftplib
import gzip
import csv
import shutil
import logging
from datetime import datetime
from django.core.management.base import BaseCommand
from django.db import transaction
from django.utils import timezone
from api.models import PCProduct

# === [ãƒ¡ãƒ¼ã‚«ãƒ¼ãƒ»ãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹è¨­å®š] ===
# 2026/01/16ç‰ˆ CSVãƒªã‚¹ãƒˆã«åŸºã¥ãã€PCãƒ»å®¶é›»é–¢é€£ã‚’ä¸­å¿ƒã«å…¨MIDã‚’ãƒãƒƒãƒ”ãƒ³ã‚°
MAKER_MAP = {
    "2442":  {"prefix": "e87",      "maker": "e87.com(åƒè¶£ä¼šã‚¤ã‚¤ãƒãƒŠ)"},
    "2543":  {"prefix": "fujitsu",  "maker": "å¯Œå£«é€š WEB MART"},
    "2557":  {"prefix": "dell",     "maker": "ãƒ‡ãƒ«æ ªå¼ä¼šç¤¾"},
    "2563":  {"prefix": "nissen",   "maker": "ãƒ‹ãƒƒã‚»ãƒ³"},
    "2633":  {"prefix": "sourcenext", "maker": "ã‚½ãƒ¼ã‚¹ãƒã‚¯ã‚¹ãƒˆ"},
    "2780":  {"prefix": "nec",      "maker": "NECã€Œå¾—é¸è¡—ã€"},
    "2880":  {"prefix": "hmv",      "maker": "HMV&BOOKS online"},
    "2928":  {"prefix": "belle",    "maker": "ãƒ™ãƒ«ãƒ¡ã‚¾ãƒ³ãƒãƒƒãƒˆ"},
    "3039":  {"prefix": "cecile",   "maker": "ã‚»ã‚·ãƒ¼ãƒ«"},
    "3256":  {"prefix": "eizo",     "maker": "EIZOãƒ€ã‚¤ãƒ¬ã‚¯ãƒˆ"},
    "13730": {"prefix": "edion",    "maker": "ã‚¨ãƒ‡ã‚£ã‚ªãƒ³ãƒãƒƒãƒˆã‚·ãƒ§ãƒƒãƒ—"},
    "13786": {"prefix": "fanccl",   "maker": "ãƒ•ã‚¡ãƒ³ã‚±ãƒ«ã‚ªãƒ³ãƒ©ã‚¤ãƒ³"},
    "13972": {"prefix": "yamada",   "maker": "ãƒ¤ãƒãƒ€ã‚¦ã‚§ãƒ–ã‚³ãƒ "},
    "13993": {"prefix": "kojima",   "maker": "ã‚³ã‚¸ãƒãƒãƒƒãƒˆ"},
    "14050": {"prefix": "tsukumo",  "maker": "ãƒ„ã‚¯ãƒ¢ãƒãƒƒãƒˆã‚·ãƒ§ãƒƒãƒ—"},
    "24361": {"prefix": "look",     "maker": "LOOK@E-SHOP"},
    "24501": {"prefix": "felissimo", "maker": "ãƒ•ã‚§ãƒªã‚·ãƒ¢"},
    "24577": {"prefix": "onward",   "maker": "ONWARD CROSSET"},
    "35265": {"prefix": "takasago", "maker": "é«˜ç ‚ç†±å­¦ã‚ªãƒ³ãƒ©ã‚¤ãƒ³ã‚·ãƒ§ãƒƒãƒ—"},
    "35340": {"prefix": "asics",    "maker": "ã‚¢ã‚·ãƒƒã‚¯ã‚¹ã‚ªãƒ³ãƒ©ã‚¤ãƒ³ã‚¹ãƒˆã‚¢"},
    "35364": {"prefix": "mizuno",   "maker": "ãƒŸã‚ºãƒå…¬å¼ã‚ªãƒ³ãƒ©ã‚¤ãƒ³"},
    "35909": {"prefix": "hp",       "maker": "HP Directplus"},
    "36009": {"prefix": "p-one",    "maker": "P-oneãƒ¢ãƒ¼ãƒ«"},
    "36187": {"prefix": "dospara",  "maker": "ãƒ‰ã‚¹ãƒ‘ãƒ©"},
    "36426": {"prefix": "matsukiyo", "maker": "ãƒãƒ„ãƒ¢ãƒˆã‚­ãƒ¨ã‚·å…¬å¼"},
    "36508": {"prefix": "dynabook", "maker": "Dynabook Direct"},
    "36559": {"prefix": "suntory",  "maker": "ã‚µãƒ³ãƒˆãƒªãƒ¼ã‚¦ã‚¨ãƒ«ãƒã‚¹å…¬å¼"},
    "36806": {"prefix": "lenovo",   "maker": "ãƒ¬ãƒãƒœãƒ»ã‚¸ãƒ£ãƒ‘ãƒ³"},
    "37641": {"prefix": "sofmap",   "maker": "ã‚½ãƒ•ãƒãƒƒãƒ—ãƒ»ãƒ‰ãƒƒãƒˆã‚³ãƒ "},
    "37667": {"prefix": "esthe",    "maker": "ã‚¨ã‚¹ãƒ†ãƒ—ãƒ­ãƒ»ãƒ©ãƒœå…¬å¼"},
    "38221": {"prefix": "mouse",    "maker": "ãƒã‚¦ã‚¹ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ãƒ¼"},
    "39165": {"prefix": "crocs",    "maker": "ã‚¯ãƒ­ãƒƒã‚¯ã‚¹å…¬å¼"},
    "39942": {"prefix": "apple",    "maker": "Appleå…¬å¼ã‚µã‚¤ãƒˆ"},
    "40386": {"prefix": "ankey",    "maker": "Anker Japanå…¬å¼ã‚µã‚¤ãƒˆ"},
    "40622": {"prefix": "sony",     "maker": "ã‚½ãƒ‹ãƒ¼ã‚¹ãƒˆã‚¢"},
    "41679": {"prefix": "buffalo",  "maker": "ãƒãƒƒãƒ•ã‚¡ãƒ­ãƒ¼å…¬å¼"},
    "42127": {"prefix": "lenovo_c", "maker": "Lenovo åºƒå‘Šé™å®šã‚¹ãƒˆã‚¢"},
    "42368": {"prefix": "asus",     "maker": "ASUS Online Store"},
    "42376": {"prefix": "iherb",    "maker": "iHerb"},
    "42408": {"prefix": "microsoft", "maker": "Microsoft Store"},
    "42549": {"prefix": "s-sneakers", "maker": "S-SNEAKERS"},
    "42687": {"prefix": "nojima",   "maker": "ãƒã‚¸ãƒã‚ªãƒ³ãƒ©ã‚¤ãƒ³"},
    "42884": {"prefix": "sanwa",    "maker": "ã‚µãƒ³ãƒ¯ãƒ€ã‚¤ãƒ¬ã‚¯ãƒˆ"},
    "43098": {"prefix": "edion_a",  "maker": "ã‚¨ãƒ‡ã‚£ã‚ªãƒ³(Affiliate)"},
    "43219": {"prefix": "trend",    "maker": "ãƒˆãƒ¬ãƒ³ãƒ‰ãƒã‚¤ã‚¯ãƒ­"},
    "43618": {"prefix": "adobe",    "maker": "Adobeå…¬å¼"},
    "43708": {"prefix": "asus_s",   "maker": "ASUS Store Online"},
    "43742": {"prefix": "petgo",    "maker": "ãƒšãƒƒãƒˆã‚´ãƒ¼"},
    "44144": {"prefix": "casetify", "maker": "CASETiFY"},
    "44632": {"prefix": "webpo",    "maker": "ã‚¦ã‚§ãƒ–ãƒ"},
    "45396": {"prefix": "coen",     "maker": "coen ONLINE STORE"},
    "45802": {"prefix": "tatras",   "maker": "TATRAS CONCEPT STORE"},
    "46274": {"prefix": "freaks",   "maker": "FREAK'S STORE"},
    "46704": {"prefix": "readyfor", "maker": "READYFOR"},
    "47492": {"prefix": "isetan",   "maker": "ISETAN BEAUTY"},
    "47506": {"prefix": "mitsukoshi", "maker": "ä¸‰è¶Šä¼Šå‹¢ä¸¹ã‚ªãƒ³ãƒ©ã‚¤ãƒ³ã‚¹ãƒˆã‚¢"},
    "47673": {"prefix": "honeys",   "maker": "Honeyså…¬å¼é€šè²©"},
    "47858": {"prefix": "united",   "maker": "UNITED ARROWS"},
    "50052": {"prefix": "loft",     "maker": "ãƒ­ãƒ•ãƒˆå…¬å¼"},
    "50342": {"prefix": "muji",     "maker": "ç„¡å°è‰¯å“"},
    "50416": {"prefix": "sogo",     "maker": "è¥¿æ­¦ãƒ»ãã”ã†ã®e.ãƒ‡ãƒ‘ãƒ¼ãƒˆ"},
    "50572": {"prefix": "jshoppers", "maker": "JSHOPPERS"},
    "50588": {"prefix": "tokyu",    "maker": "æ±æ€¥ç™¾è²¨åº—ãƒãƒƒãƒˆã‚·ãƒ§ãƒƒãƒ”ãƒ³ã‚°"},
    "50644": {"prefix": "takashimaya", "maker": "é«˜å³¶å±‹ã‚ªãƒ³ãƒ©ã‚¤ãƒ³ã‚¹ãƒˆã‚¢"},
    "50692": {"prefix": "daimaru",  "maker": "å¤§ä¸¸æ¾å‚å±‹ã‚ªãƒ³ãƒ©ã‚¤ãƒ³ã‚¹ãƒˆã‚¢"},
    "50818": {"prefix": "hankyu",   "maker": "é˜ªæ€¥ç™¾è²¨åº—ã‚ªãƒ³ãƒ©ã‚¤ãƒ³ã‚¹ãƒˆã‚¢"},
    "52983": {"prefix": "kinokuniya", "maker": "ç´€ä¼Šåœ‹å±‹æ›¸åº—"},
    "53011": {"prefix": "tsutaya",  "maker": "TSUTAYA ã‚ªãƒ³ãƒ©ã‚¤ãƒ³ã‚·ãƒ§ãƒƒãƒ”ãƒ³ã‚°"},
    "53146": {"prefix": "bookoff",  "maker": "ãƒ–ãƒƒã‚¯ã‚ªãƒ•å…¬å¼ã‚ªãƒ³ãƒ©ã‚¤ãƒ³"},
    "53216": {"prefix": "netoff",   "maker": "ãƒãƒƒãƒˆã‚ªãƒ•"},
    "53442": {"prefix": "surugaya", "maker": "é§¿æ²³å±‹"},
    "53445": {"prefix": "amiami",   "maker": "ã‚ã¿ã‚ã¿"},
    "53500": {"prefix": "animate",  "maker": "ã‚¢ãƒ‹ãƒ¡ã‚¤ãƒˆé€šè²©"},
}

logger = logging.getLogger(__name__)

class Command(BaseCommand):
    help = "LinkShare FTPã‹ã‚‰è£½å“ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã—ã€PCè£½å“ã®ã¿ã‚’DBã«ä¿å­˜ã—ã¾ã™ã€‚"

    FTP_HOST = os.getenv("LINKSHARE_FTP_HOST", "aftp.linksynergy.com")
    FTP_USER = os.getenv("LINKSHARE_BC_USER", "rkp_3273700")
    FTP_PASS = os.getenv("LINKSHARE_BC_PASS", "5OqF1NfuruvJlmuJXKQDRuzh")
    DOWNLOAD_DIR = "/tmp/linkshare_import"

    def add_arguments(self, parser):
        parser.add_argument('--mids', type=str, help='MIDã‚’ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šã§æŒ‡å®š')
        parser.add_argument('--limit', type=int, default=10, help='å‡¦ç†ã™ã‚‹ãƒ¡ãƒ¼ã‚«ãƒ¼æ•°')
        parser.add_argument('--force', action='store_true', help='æ—¢å­˜ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç„¡è¦–ã—ã¦DL')

    def handle(self, *args, **options):
        self.stdout.write(self.style.SUCCESS(f"ğŸš€ LinkShare Sync Started: {timezone.now()}"))
        os.makedirs(self.DOWNLOAD_DIR, exist_ok=True)

        ftp = self._connect_ftp()
        if not ftp: return

        try:
            # 1. FTPèµ°æŸ» (_template.txt.gz ã¯é™¤å¤–ã€å®Ÿä½“ãƒ•ã‚¡ã‚¤ãƒ«ã®ã¿)
            mid_files = self._scan_ftp_files(ftp, options['mids'])
            self._print_summary_table(mid_files)

            if not mid_files:
                self.stdout.write(self.style.WARNING("âš ï¸ å¯¾è±¡ã¨ãªã‚‹å®Ÿãƒ‡ãƒ¼ã‚¿(mp.txt.gz)ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚"))
                return

            # 2. ãƒ¡ã‚¤ãƒ³å‡¦ç†
            processed = 0
            for mid, filename, f_type, f_size, path in mid_files:
                if processed >= options['limit']: break
                
                info = MAKER_MAP.get(mid, {"prefix": f"mid_{mid}", "maker": f"Unknown({mid})"})
                local_gz = os.path.join(self.DOWNLOAD_DIR, filename)
                local_txt = local_gz.replace('.gz', '.txt')

                self.stdout.write(f"\n>>> Processing: {info['maker']} ({mid})")

                if not options['force'] and os.path.exists(local_gz) and os.path.getsize(local_gz) == f_size:
                    self.stdout.write(f"â© Cached: {filename}")
                else:
                    if not self._download(ftp, path, filename, local_gz): continue

                if self._decompress(local_gz, local_txt):
                    count = self._parse_and_save(local_txt, mid, info)
                    self.stdout.write(self.style.SUCCESS(f"âœ… {count} items stored."))
                    processed += 1
                    if os.path.exists(local_txt): os.remove(local_txt)

            self.stdout.write(self.style.SUCCESS(f"\nâœ¨ åŒæœŸå®Œäº†: {processed} ã‚µã‚¤ãƒˆã®å‡¦ç†ã«æˆåŠŸã—ã¾ã—ãŸã€‚"))

        finally:
            ftp.quit()

    def _scan_ftp_files(self, ftp, target_mids_str):
        """å®Ÿãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ« (*_mp.txt.gz) ã®ã¿ã‚’å–å¾—"""
        target_mids = target_mids_str.split(',') if target_mids_str else []
        results = {}
        # _template ã‚’å«ã¾ãªã„æ­£è¦ã®å®Ÿãƒ•ã‚¡ã‚¤ãƒ«ã‚’æŠ½å‡ºã™ã‚‹æ­£è¦è¡¨ç¾
        pattern = re.compile(r"^(\d+)_3273700_(mp|delta)\.txt\.gz$")

        try:
            ftp.voidcmd('TYPE I')
            ftp.cwd("/")
            files = ftp.nlst()
            for f in files:
                match = pattern.search(f)
                if not match: continue
                
                mid, suffix = match.groups()
                if target_mids and mid not in target_mids: continue
                
                try: f_size = ftp.size(f)
                except: f_size = 0
                
                # 0ãƒã‚¤ãƒˆã‚„ç©ºã®ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’é™¤å¤–
                if f_size > 100: 
                    f_type = "FULL" if suffix == "mp" else "DELTA"
                    if mid not in results or f_type == "FULL":
                        results[mid] = (mid, f, f_type, f_size, "/")
        except Exception as e:
            self.stderr.write(f"âŒ FTP Scan Error: {e}")
        
        return sorted(results.values(), key=lambda x: x[0])

    def _download(self, ftp, path, filename, local_path):
        try:
            ftp.voidcmd('TYPE I')
            ftp.cwd(path)
            with open(local_path, 'wb') as f:
                ftp.retrbinary(f'RETR {filename}', f.write)
            return True
        except Exception as e:
            self.stderr.write(f"âŒ Download error: {e}")
            return False

    def _decompress(self, gz_path, txt_path):
        try:
            with gzip.open(gz_path, 'rb') as f_in, open(txt_path, 'wb') as f_out:
                shutil.copyfileobj(f_in, f_out)
            return True
        except Exception as e:
            self.stderr.write(f"âŒ Gzip error: {e}")
            return False

    def _parse_and_save(self, file_path, mid, info):
        batch = []
        imported_count = 0
        # å•†å“åã€å‹ç•ªã€ä¾¡æ ¼ã€URLã€ç”»åƒURLã®åˆ—ã‚’æŠ½å‡º
        with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
            reader = csv.reader(f, delimiter='|')
            try: next(reader)
            except: return 0
            
            for row in reader:
                if not row or row[0] == 'TRL' or len(row) < 18: continue
                
                name, sku = row[1].strip(), row[2].strip()
                raw_desc = (row[9] or row[10] or "").strip()
                
                # PCãƒ»ãƒ¢ãƒ‹ã‚¿ãƒ¼é–¢é€£ã®ã¿ãƒ•ã‚£ãƒ«ã‚¿
                keywords = ['pc', 'laptop', 'ãƒ‘ã‚½ã‚³ãƒ³', 'ãƒãƒ¼ãƒˆ', 'monitor', 'ãƒ‡ã‚£ã‚¹ãƒ—ãƒ¬ã‚¤', 'desktop', 'ãƒ¯ãƒ¼ã‚¯ã‚¹ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³']
                if not any(k in (name + raw_desc).lower() for k in keywords):
                    continue

                price = self._clean_price(row[13])
                specs = self._extract_specs(f"{name} {raw_desc}")

                batch.append(PCProduct(
                    unique_id=f"{info['prefix']}_{sku}",
                    site_prefix=info['prefix'],
                    maker=info['maker'],
                    name=name, price=price,
                    url=row[8].strip(), image_url=row[6].strip(), affiliate_url=row[5].strip(),
                    description=f"{specs} / {raw_desc}"[:1000],
                    unified_genre=self._judge_genre(name, row[17]),
                    is_active=True, updated_at=timezone.now()
                ))

                if len(batch) >= 200:
                    self._bulk_upsert(batch)
                    imported_count += len(batch)
                    batch = []

            if batch:
                self._bulk_upsert(batch)
                imported_count += len(batch)
        return imported_count

    def _extract_specs(self, text):
        cpu = re.search(r'(Core\s?i[3579]|Ryzen\s?[3579]|Ultra\s?\d|M[123])', text, re.I)
        ram = re.search(r'(\d+)\s?GB\s?(?:RAM|ãƒ¡ãƒ¢ãƒª)', text, re.I)
        ssd = re.search(r'(\d+)\s?(?:GB|TB)\s?(?:SSD|NVMe|ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸)', text, re.I)
        res = [m.group(0) for m in [cpu, ram, ssd] if m]
        return " / ".join(res)

    def _judge_genre(self, name, cat):
        n = name.lower()
        if any(x in n for x in ["monitor", "ãƒ¢ãƒ‹ã‚¿ãƒ¼", "ãƒ‡ã‚£ã‚¹ãƒ—ãƒ¬ã‚¤"]): return "Monitor"
        if any(x in n for x in ["laptop", "ãƒãƒ¼ãƒˆ"]): return "Laptop"
        if any(x in n for x in ["desktop", "ãƒ‡ã‚¹ã‚¯ãƒˆãƒƒãƒ—"]): return "Desktop"
        return "PC"

    def _clean_price(self, p_str):
        try: return int(float(re.sub(r'[^\d.]', '', p_str)))
        except: return 0

    def _bulk_upsert(self, batch):
        with transaction.atomic():
            for item in batch:
                PCProduct.objects.update_or_create(
                    unique_id=item.unique_id,
                    defaults={
                        'maker': item.maker, 'name': item.name, 'price': item.price,
                        'url': item.url, 'image_url': item.image_url, 'affiliate_url': item.affiliate_url,
                        'description': item.description, 'unified_genre': item.unified_genre,
                        'is_active': True, 'updated_at': item.updated_at
                    }
                )

    def _connect_ftp(self):
        try:
            ftp = ftplib.FTP(self.FTP_HOST, timeout=60)
            ftp.login(self.FTP_USER, self.FTP_PASS)
            ftp.set_pasv(True)
            return ftp
        except Exception as e:
            self.stderr.write(f"âŒ FTP Connection Fail: {e}")
            return None

    def _print_summary_table(self, mid_files):
        self.stdout.write("\n" + "="*100)
        self.stdout.write(f"{'MID':<10} | {'Manufacturer Name (Updated)':<30} | {'Type':<6} | {'Size(MB)':<10}")
        self.stdout.write("-" * 100)
        for mid, fname, f_type, f_size, path in mid_files:
            m_name = MAKER_MAP.get(mid, {}).get('maker', f'Unknown({mid})')
            size_mb = f"{f_size / 1024**2:,.2f}"
            self.stdout.write(f"{mid:<10} | {m_name[:30]:<30} | {f_type:<6} | {size_mb:<10}")
        self.stdout.write("="*100 + "\n")